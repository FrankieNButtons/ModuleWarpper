{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27173dc2",
   "metadata": {},
   "source": [
    "# <center>我整个重写一遍吧"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbadca16",
   "metadata": {},
   "source": [
    "## 所有用到的环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21e04e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools;\n",
    "import time;\n",
    "import types;\n",
    "import typing;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8971aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdbd1e8",
   "metadata": {},
   "source": [
    "## 代码兼容性评估"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5091c051",
   "metadata": {},
   "source": [
    "### Some General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b10464cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('torch.optim.Adam.Adam', 'torch.mul')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getAPIName(api):\n",
    "    # for function type\n",
    "    if isinstance(api, types.FunctionType) or isinstance(api, types.BuiltinFunctionType):\n",
    "        apiName = api.__module__ + \".\" + api.__name__;\n",
    "        return apiName;\n",
    "    # for class type\n",
    "    elif isinstance(api, type):\n",
    "        apiName = api.__module__;\n",
    "        if api.__name__[-len(api.__name__)+1:] == apiName[-len(api.__name__)+1:]:\n",
    "            apiName = apiName[:-len(api.__name__)] + api.__name__;\n",
    "        apiName = apiName + \".\" + api.__name__;\n",
    "        return apiName;\n",
    "    # for module type\n",
    "    elif isinstance(api, types.ModuleType):\n",
    "        return api.__name__;\n",
    "    # \n",
    "    elif api.__module__ == \"typing\":\n",
    "        apiName = api.__module__ + \".\" + api.__name__;\n",
    "        return apiName;\n",
    "    else:\n",
    "        return str(type(api));\n",
    "getAPIName(torch.optim.Adam),getAPIName(torch.mul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e21ecd99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, module)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def isFromModule(api: types.FunctionType, module: str):\n",
    "    return getAPIName(api).startswith(module);\n",
    "isFromModule(torch._utils, \"torch\"),type(torch.optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68cb49f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adadelta',\n",
       " 'Adagrad',\n",
       " 'Adam',\n",
       " 'AdamW',\n",
       " '_functional',\n",
       " 'SparseAdam',\n",
       " 'Adamax',\n",
       " 'ASGD',\n",
       " 'SGD',\n",
       " 'RAdam',\n",
       " 'Rprop',\n",
       " 'RMSprop',\n",
       " 'Optimizer',\n",
       " 'NAdam',\n",
       " 'LBFGS',\n",
       " 'lr_scheduler',\n",
       " 'swa_utils',\n",
       " '_multi_tensor']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def getAttributes(module):\n",
    "#     return [i for i in dir(module) if not i.startswith(\"__\") and callable(getattr(module, i)) or isinstance(getattr(module, i), types.ModuleType)];\n",
    "# getAttributes(torch.optim)\n",
    "def getAttributes(module):\n",
    "    attributes = [];\n",
    "    for i in module.__dict__.keys():\n",
    "        if not i.startswith(\"__\"):\n",
    "            try:\n",
    "                attr = getattr(module, i);\n",
    "                if callable(attr) or isinstance(attr, types.ModuleType):\n",
    "                    attributes.append(i);\n",
    "            except AttributeError:\n",
    "                continue;\n",
    "            except Exception as e:\n",
    "                print(f\"Error accessing attribute {i} of {module}: {e}\");\n",
    "                continue;\n",
    "    return attributes;\n",
    "getAttributes(torch.optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400f88e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "194996dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['total',\n",
       " 'most_common',\n",
       " 'elements',\n",
       " 'fromkeys',\n",
       " 'update',\n",
       " 'subtract',\n",
       " 'copy',\n",
       " '_keep_positive']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAttributes(torch.optim.lr_scheduler.Counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e622e933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('torch', 'torch.optim', 'torch._C')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor.__module__,getAPIName(torch.optim),torch._C.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a95d150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def isDecorated(obj: (types.FunctionType, types.ModuleType, type)):\n",
    "    return getattr(obj, \"_isDecorated\", False);\n",
    "isDecorated(torch.tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3870fd",
   "metadata": {},
   "source": [
    "### Some General Decorators Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ba8470",
   "metadata": {},
   "source": [
    "#### 需要的环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2915be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools;\n",
    "import time;\n",
    "import types;\n",
    "import warnings;\n",
    "import sys;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb493bdb",
   "metadata": {},
   "source": [
    "#### TimerDecorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58dd2c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TimerDecorator(func: types.FunctionType):\n",
    "    \"\"\"\n",
    "    **Description**\n",
    "    A running timer for a function.\n",
    "    \n",
    "    **params**\n",
    "    func(String): the function to be timed.\n",
    "    \n",
    "    **returns**\n",
    "    wrapper: a timer decorated function.\n",
    "    \"\"\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        startTime = time.perf_counter_ns();\n",
    "        result = func(*args, **kwargs);\n",
    "        endTime = time.perf_counter_ns();\n",
    "        costTime = (endTime - startTime) / 1000 / 1000;\n",
    "        timeLog = f\"{func.__name__}() cost {costTime} ms\";\n",
    "        # print(timeLog);\n",
    "        return result, str(startTime), costTime;\n",
    "    return wrapper;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbf3d51",
   "metadata": {},
   "source": [
    "Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6a1755c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[23.0800, 23.0500],\n",
       "          [43.4516, 48.1955]]),\n",
       "  '102845888299300',\n",
       "  0.1584),\n",
       " '%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%',\n",
       " (120, '102845888487100', 0.0024))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tst():\n",
    "    t = 1;\n",
    "    for i in range(5):\n",
    "        t *= (i+1);\n",
    "    return t;\n",
    "\n",
    "TimerDecorator(torch.matmul)(torch.tensor([[1.0,5.0],[3.07,7.29]]), torch.tensor([[6.08,9.05],[3.4,2.8]])), \"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\",\\\n",
    "TimerDecorator(tst)()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca59dd2",
   "metadata": {},
   "source": [
    "#### APIDecorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8357c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def APIDecorator(func: str, module: str=None):\n",
    "    \"\"\"\n",
    "    **Description**\n",
    "    A API usage recorder for a function.\n",
    "    \n",
    "    **params**\n",
    "    func(String): the function to be recorded.\n",
    "    \n",
    "    **returns**\n",
    "    wrapper: a API usage recored function.\n",
    "    \"\"\"\n",
    "    apiName = getAPIName(func)\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        apiName = getAPIName(func)\n",
    "        result, startTimestamp, costTime= TimerDecorator(func)(*args, **kwargs);\n",
    "        print(f\"{apiName} starts from {startTimestamp} costs {costTime}ms.\");\n",
    "        return result, apiName, startTimestamp, costTime;\n",
    "    if module == None:\n",
    "        return wrapper;\n",
    "    elif isFromModule(func, module):\n",
    "        return wrapper;\n",
    "    else:\n",
    "        # raise ValueError(f\"the function `{apiName}` is not from module `{module}`\");\n",
    "        return func;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606c9ad9",
   "metadata": {},
   "source": [
    "Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c031b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.randn starts from 102845902581700 costs 0.0497ms.\n",
      "torch.mul starts from 102845902730000 costs 0.1343ms.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([-1.2677, -0.6425]),\n",
       " '%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%',\n",
       " (tensor([[1.5157, 1.7160, 0.5315],\n",
       "          [1.6908, 0.0873, 0.4804]]),\n",
       "  'torch.randn',\n",
       "  '102845902581700',\n",
       "  0.0497),\n",
       " '%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%',\n",
       " (tensor([ 5.,  0.,  2., 12.]), 'torch.mul', '102845902730000', 0.1343))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "APIDecorator(torch.normal, \"types\")(torch.tensor([0,0.01])), \"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\", \\\n",
    "APIDecorator(torch.randn, \"torch\")([2,3]), \"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\", \\\n",
    "APIDecorator(torch.mul)(torch.tensor([2.5,0,1,3]), torch.tensor([2,0.9,2,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3786915c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.optim'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.optim.__name__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f3d5ad",
   "metadata": {},
   "source": [
    "### Class TorchWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c4d88",
   "metadata": {},
   "source": [
    "#### 需要的环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c39f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools;\n",
    "import time;\n",
    "import types;\n",
    "import json;\n",
    "import os;\n",
    "import operator;\n",
    "import pandas as pd;\n",
    "import torch;\n",
    "import sys;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42942f99",
   "metadata": {},
   "source": [
    "#### TorchWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5f54f1",
   "metadata": {},
   "source": [
    "```\n",
    "*****************************\n",
    "The Structure For callRecords\n",
    "*****************************\n",
    "callRecords\n",
    "│\n",
    "├── API_1\n",
    "│   │\n",
    "│   ├── TotalTime(ms): 150.0\n",
    "│   │\n",
    "│   ├── 1\n",
    "│   │   ├── detailedAPIName: \n",
    "│   │   ├── StartTimestamp: 1625150800123456789\n",
    "│   │   ├── CostTime(ms): 50.0\n",
    "│   │   └── Arguments: (arg1, arg2, ...)\n",
    "│   │\n",
    "│   ├── 2\n",
    "│   │   ├── detailedAPIName: \n",
    "│       ├── StartTimestamp: 1625150860123456789\n",
    "│       ├── CostTime(ms): 100.0\n",
    "│       └── Arguments: (arg1, arg2, ...)\n",
    "│\n",
    "├── API_2\n",
    "│   │\n",
    "│   ├── TotalTime(ms): 200.0\n",
    "│   │\n",
    "│   ├── 1\n",
    "│   │   ├── detailedAPIName: \n",
    "│       ├── StartTimestamp: 1625150900123456789\n",
    "│       ├── CostTime(ms): 200.0\n",
    "│       └── Arguments: (arg1, arg2, ...)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4c7db92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchWrapper:\n",
    "    \"\"\"\n",
    "    A wrapper class for torch functions and modules to record API call details.\n",
    "    \"\"\"\n",
    "        \n",
    "    \"\"\"\n",
    "    ********************\n",
    "    Initializing Section\n",
    "    ********************\n",
    "    \"\"\"\n",
    "\n",
    "    GOAL_MODULE = \"torch\";\n",
    "    DEFAULT_PATH = \"./results\"\n",
    "    DEFAULT_FORMAT = \"csv\";\n",
    "    DEFAULT_NAME_SPEC = \"timestamp\";\n",
    "    SUPPORTED_FORMATS = [\"json\", \"csv\", \"html\", \"xlsx\"];\n",
    "    SUPPORTED_NAME_SPEC = [\"timestamp\", \"datetime\", \"serial\"];\n",
    "\n",
    "    class ConfigKey:\n",
    "        GOAL_MODULE = \"goal_module\";\n",
    "        OUT_DIR = \"out_dir\";\n",
    "        FORMAT = \"format\";\n",
    "        FILE_MAX_SIZE = \"file_max_size\";\n",
    "        FILE_NAME_SPEC = \"file_name_spec\";\n",
    "\n",
    "    class CallRecordKey:\n",
    "        API_NAME = \"APIName\";\n",
    "\n",
    "        class ResultKey:\n",
    "            TOTAL_TIME = \"TotalTime(ms)\";\n",
    "            CALL_NUMBER = \"CallNumber\";\n",
    "            START_TIMESTAMP = \"StartTimestamp\";\n",
    "            COST_TIME = \"CostTime(ms)\";\n",
    "            ARGUMENTS = \"Arguments\";\n",
    "\n",
    "    def __init__(self, config: dict):\n",
    "        \"\"\"\n",
    "        Initialize the TorchWrapper with the provided configuration.\n",
    "        \n",
    "        **params**\n",
    "        config (dict): The configuration dictionary.\n",
    "        \"\"\"\n",
    "        self.callRecords = {};\n",
    "        self.config = self.parseConfig(config);\n",
    "        print(f\"your wrapper config: {self.getConfig()}\");\n",
    "        \n",
    "\n",
    "    def parseConfig(self, config: dict) -> dict:\n",
    "        \"\"\"\n",
    "        Parse and validate the configuration dictionary.\n",
    "        \n",
    "        **params**\n",
    "        config (dict): The configuration dictionary.\n",
    "        \n",
    "        **returns**\n",
    "        dict: The parsed and validated configuration.\n",
    "        \n",
    "        **raises**\n",
    "        ValueError: If any required configuration is invalid.\n",
    "        \"\"\"\n",
    "        if TorchWrapper.ConfigKey.OUT_DIR not in config:\n",
    "            raise ValueError(\"Output directory is required.\");\n",
    "        assert isinstance(config[TorchWrapper.ConfigKey.OUT_DIR], str);\n",
    "\n",
    "        if TorchWrapper.ConfigKey.FORMAT in config:\n",
    "            assert isinstance(config[TorchWrapper.ConfigKey.FORMAT], str);\n",
    "            format = config[TorchWrapper.ConfigKey.FORMAT];\n",
    "            if format not in TorchWrapper.SUPPORTED_FORMATS:\n",
    "                raise ValueError(f\"Unsupported format {format} for saving result\");\n",
    "        else:\n",
    "            config[TorchWrapper.ConfigKey.FORMAT] = TorchWrapper.DEFAULT_FORMAT;\n",
    "\n",
    "        if TorchWrapper.ConfigKey.FILE_MAX_SIZE in config:\n",
    "            assert isinstance(config[TorchWrapper.ConfigKey.FILE_MAX_SIZE], str);\n",
    "            if config[TorchWrapper.ConfigKey.FILE_MAX_SIZE][-2:] not in [\"KB\", \"MB\", \"GB\"]:\n",
    "                raise ValueError(\"maxSize should be defined in the style of `myInt`KB/MB/GB\");\n",
    "\n",
    "        if TorchWrapper.ConfigKey.FILE_NAME_SPEC in config:\n",
    "            assert isinstance(config[TorchWrapper.ConfigKey.FILE_NAME_SPEC], str);\n",
    "            name_spec = config[TorchWrapper.ConfigKey.FILE_NAME_SPEC];\n",
    "            if name_spec not in TorchWrapper.SUPPORTED_NAME_SPEC:\n",
    "                raise ValueError(f\"Unsupported file name spec {name_spec}\");\n",
    "        else:\n",
    "            config[TorchWrapper.ConfigKey.FILE_NAME_SPEC] = TorchWrapper.DEFAULT_NAME_SPEC;\n",
    "\n",
    "        return config;\n",
    "\n",
    "    def getConfig(self) -> dict:\n",
    "        return self.config;\n",
    "    \n",
    "    \"\"\"\n",
    "    ******************\n",
    "    decorating Section\n",
    "    ******************\n",
    "    \"\"\"\n",
    "\n",
    "    def CountDecorator(self, func: types.FunctionType) -> types.FunctionType:\n",
    "        \"\"\"\n",
    "        A decorator that counts the calls of a function and records it.\n",
    "        \n",
    "        **params**\n",
    "        func (types.FunctionType): The function to be recorded calling times.\n",
    "        \n",
    "        **returns**\n",
    "        types.FunctionType: A function that has been counted calling times.\n",
    "        \"\"\"\n",
    "        funcName = getAPIName(func);\n",
    "        # print(f\"decorating function {funcName}\");\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            record = {\n",
    "                TorchWrapper.CallRecordKey.ResultKey.CALL_NUMBER: None,\n",
    "                TorchWrapper.CallRecordKey.ResultKey.START_TIMESTAMP: None,\n",
    "                TorchWrapper.CallRecordKey.ResultKey.COST_TIME: None,\n",
    "                TorchWrapper.CallRecordKey.ResultKey.ARGUMENTS: (args, kwargs)\n",
    "            };\n",
    "\n",
    "            result, apiName, startTimestamp, costTime = APIDecorator(func)(*args, **kwargs);\n",
    "            if apiName in self.callRecords:\n",
    "                callCount = len(self.callRecords[apiName].keys());\n",
    "                totalTime = self.callRecords[apiName][TorchWrapper.CallRecordKey.ResultKey.TOTAL_TIME];\n",
    "            else:\n",
    "                callCount = 1;\n",
    "                totalTime = 0.0;\n",
    "\n",
    "            record[TorchWrapper.CallRecordKey.ResultKey.START_TIMESTAMP] = startTimestamp;\n",
    "            record[TorchWrapper.CallRecordKey.ResultKey.COST_TIME] = costTime;\n",
    "            totalTime += costTime;\n",
    "\n",
    "            self.callRecords.setdefault(apiName, {})[TorchWrapper.CallRecordKey.ResultKey.TOTAL_TIME] = totalTime;\n",
    "            self.callRecords[apiName][callCount] = record;\n",
    "\n",
    "            return result;\n",
    "        wrapper._isDecorated = True;\n",
    "        # print(f\"{funcName} decorated.\");\n",
    "        return wrapper;\n",
    "    \n",
    "    def decorateFunction(self, module: (types.ModuleType, type), name: str, func: (types.FunctionType, types.BuiltinFunctionType)):\n",
    "        setattr(module, name, self.CountDecorator(func));\n",
    "\n",
    "    def decorateClass(self, cls: type):\n",
    "        \"\"\"\n",
    "        Decorates all methods of a class with CountDecorator and records the API names.\n",
    "\n",
    "        **params**\n",
    "        cls (type): The class whose methods are to be decorated with CountDecorator.\n",
    "\n",
    "        **returns**\n",
    "        None\n",
    "        \"\"\"\n",
    "        clsName = cls.__module__ + \".\" + cls.__name__;\n",
    "        if isFromModule(cls, TorchWrapper.GOAL_MODULE):\n",
    "            assert isinstance(cls, type), f\"`{cls}` must be a class.\";\n",
    "\n",
    "            if isDecorated(cls):\n",
    "                return ; # Stop decoration don't need specific returns\n",
    "            print(f\"\\t[Class] Class `{clsName}` is not decorated, decorate it.\");\n",
    "\n",
    "            attributes = getAttributes(cls);\n",
    "            if attributes:\n",
    "                for name in attributes:\n",
    "                    try:\n",
    "                        cls._isDecorated = True;\n",
    "                        cattr = getattr(cls, name);\n",
    "                        apiName = getAPIName(cattr);\n",
    "                        if isinstance(cattr, (types.FunctionType, types.BuiltinFunctionType)) and isFromModule(cattr, TorchWrapper.GOAL_MODULE) and not isDecorated(cattr):\n",
    "                            print(f\"\\t\\t[Method] Method `{name}` hasn't been decorated, \\n\\t\\tdecorating `{name}`.\");\n",
    "                            self.decorateFunction(cls, name, cattr);\n",
    "                            print(f\"\\t\\tMethod `{name}` has been decorated.\");\n",
    "                        elif isinstance(cattr, (type, types.ModuleType)) and isFromModule(cattr, TorchWrapper.GOAL_MODULE) and not isDecorated(cattr):\n",
    "                            self.decorateClass(cattr);\n",
    "\n",
    "                    except TypeError as e:\n",
    "                        if \"immutable type\" in str(e):\n",
    "                            raise TypeError(f\"\\t[IMU]`{name}` is an immutable type, out.\") from e;\n",
    "                            continue;\n",
    "                        raise NameError(f\"[decorateClass]The attribute that cause TypeError: `{name}`\") from e;\n",
    "        else:\n",
    "            print(f\"\\t[EMN]Class `{moduleName}` is a external class or subclass, not inside `{TorchWrapper.GOAL_MODULE}`, out.\");\n",
    "            return;\n",
    "\n",
    "\n",
    "    def decorateModule(self, module: types.ModuleType):\n",
    "        \"\"\"\n",
    "        Decorates all functions and classes of a module with CountDecorator.\n",
    "        \n",
    "        **params**\n",
    "        module (types.ModuleType): The module to be decorated.\n",
    "        \n",
    "        **returns**\n",
    "        None\n",
    "        \"\"\"\n",
    "        moduleName = getAPIName(module);\n",
    "        if isFromModule(module, TorchWrapper.GOAL_MODULE):\n",
    "            assert isinstance(module, types.ModuleType), f\"`{module}` must be a module.\";\n",
    "            if isDecorated(module):\n",
    "                # print(f\"module {moduleName} has been decorated, out.\");\n",
    "                return; # Stop the decoration, no specific return.\n",
    "            module._isDecorated = True;\n",
    "            for name in getAttributes(module):\n",
    "                try:\n",
    "                    mattr = getattr(module, name);\n",
    "                    apiName = getAPIName(mattr);\n",
    "                    if isinstance(mattr, types.ModuleType) and isFromModule(mattr, TorchWrapper.GOAL_MODULE):\n",
    "                        print(f\"\\t[SubModule]Submodule `{name}` of {moduleName} hasn't been decorated, \\n\\tdecorating {name}.\");\n",
    "                        self.decorateModule(mattr);\n",
    "                        if isDecorated(mattr):\n",
    "                            print(f\"\\t[SubModule]Submodule `{name}` has been decorated.\");\n",
    "                    elif isinstance(mattr, types.FunctionType) and isFromModule(mattr, TorchWrapper.GOAL_MODULE) and not isDecorated(mattr):\n",
    "                        print(f\"\\t[Operator]Operator `{apiName}` hasn't been decorated, \\n\\tdecorating {name}.\");\n",
    "                        self.decorateFunction(module, name, mattr);\n",
    "                        if isDecorated(mattr):\n",
    "                            print(f\"\\t[Operator]Opertator `{apiName}` has been decorated.\");\n",
    "                    elif isinstance(mattr, type) and isFromModule(mattr, TorchWrapper.GOAL_MODULE) and not isDecorated(mattr):\n",
    "                        print(f\"\\t[SubClass]SubClass `{name}` of {moduleName} hasn't been decorated, \\n\\tdecorating {apiName}.\");\n",
    "                        self.decorateClass(mattr);\n",
    "                        if isDecorated(mattr):\n",
    "                            print(f\"\\t[SubClass]SubClass `{name}` has been decorated.\");\n",
    "                    elif isDecorated(mattr):\n",
    "                        print(f\"\\t[Decorated]Attribute `{name}` of {moduleName} has been decorated, out.\");\n",
    "                    elif not isFromModule(mattr, TorchWrapper.GOAL_MODULE):\n",
    "                        print(f\"[EXTATTR]`{apiName}` is a external attribute, not inside `{TorchWrapper.GOAL_MODULE}`, out.\");\n",
    "                    else:\n",
    "                        print(f\"\\t[SkipDecoration]Attribute `{name}` of {moduleName} skiped decoration, for unknow reason.\");\n",
    "                except Exception as e:\n",
    "                    raise NameError(f\"[decorateModule]The attribute that cause Error: `{name}`\") from e;\n",
    "                    print(f\"The attribute that cause Error: `{name}`\");\n",
    "                    continue;\n",
    "                    \n",
    "\n",
    "        else:\n",
    "            print(f\"module {moduleName} is a external module, not in {TorchWrapper.GOAL_MODULE}, out.\");\n",
    "    \n",
    "    \"\"\"\n",
    "    ******************\n",
    "    Processing Section\n",
    "    ******************\n",
    "    \"\"\"\n",
    "    \n",
    "    def getFileMaxSize(self, config: dict) -> int:\n",
    "        \"\"\"\n",
    "        Parse the max file size limit from the configuration.\n",
    "        \n",
    "        **params**\n",
    "        config (dict): The configuration dictionary.\n",
    "        \n",
    "        **returns**\n",
    "        int: The max file size in bytes.\n",
    "        \n",
    "        **raises**\n",
    "        ValueError: If the max size format is invalid.\n",
    "        \"\"\"\n",
    "        if TorchWrapper.ConfigKey.FILE_MAX_SIZE in config:\n",
    "            maxSize = config[TorchWrapper.ConfigKey.FILE_MAX_SIZE];\n",
    "            if maxSize.endswith(\"KB\"):\n",
    "                return int(maxSize[:-2]) * 1024;\n",
    "            elif maxSize.endswith(\"MB\"):\n",
    "                return int(maxSize[:-2]) * (1024 ** 2);\n",
    "            elif maxSize.endswith(\"GB\"):\n",
    "                return int(maxSize[:-2]) * (1024 ** 3);\n",
    "            else:\n",
    "                raise ValueError(\"maxSize should be defined in the style of `myInt`KB/MB/GB(e.g.'64MB')\");\n",
    "        return None;\n",
    "\n",
    "    def getFileNameSuffix(self) -> str:\n",
    "        \"\"\"\n",
    "        Get the file name suffix based on the configuration.\n",
    "        \n",
    "        **returns**\n",
    "        str: The file name suffix.\n",
    "        \n",
    "        **raises**\n",
    "        NotImplementedError: If the file name specification is not implemented.\n",
    "        \"\"\"\n",
    "        file_name_spec = self.config[TorchWrapper.ConfigKey.FILE_NAME_SPEC];\n",
    "        if file_name_spec == \"timestamp\":\n",
    "            return str(time.time_ns());\n",
    "        elif file_name_spec == \"datetime\":\n",
    "            return time.strftime(\"%Y-%m-%d_%H-%M-%S\", time.localtime());\n",
    "        elif file_name_spec == \"serial\":\n",
    "            raise NotImplementedError(\"Serial file name specification is not implemented.\");\n",
    "        return \"\"\n",
    "\n",
    "    def setPath(self, path: str) -> str:\n",
    "        \"\"\"\n",
    "        Prepare the result saving directory.\n",
    "        \n",
    "        **params**\n",
    "        path (str): The directory path.\n",
    "        \n",
    "        **returns**\n",
    "        str: The validated directory path.\n",
    "        \n",
    "        **raises**\n",
    "        ValueError: If the path is not a directory.\n",
    "        \"\"\"\n",
    "        if os.path.exists(path):\n",
    "            if not os.path.isdir(path):\n",
    "                raise ValueError(f\"Path {path} is not a directory\");\n",
    "        else:\n",
    "            os.makedirs(path);\n",
    "        return path;\n",
    "\n",
    "    def getFileName(self, config: dict) -> str:\n",
    "        \"\"\"\n",
    "        Get the file name for saving the results.\n",
    "        \n",
    "        **returns**\n",
    "        str: The file name.\n",
    "        \"\"\"\n",
    "        suffix = self.getFileNameSuffix();\n",
    "        return f\"TorchWrapper_Result_{suffix}\";\n",
    "\n",
    "    def getDFFormattedCallRecords(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Formats the call records as a pandas DataFrame.\n",
    "        \n",
    "        **returns**\n",
    "        pd.DataFrame: The formatted call records.\n",
    "        \"\"\"\n",
    "        records = []\n",
    "        for apiName, calls in self.callRecords.items():\n",
    "            totalTime = calls.pop(TorchWrapper.CallRecordKey.ResultKey.TOTAL_TIME, 0);\n",
    "            for callNumber, call in calls.items():\n",
    "                record = {\n",
    "                    TorchWrapper.CallRecordKey.API_NAME: apiName,\n",
    "                    TorchWrapper.CallRecordKey.ResultKey.TOTAL_TIME: totalTime,\n",
    "                    TorchWrapper.CallRecordKey.ResultKey.CALL_NUMBER: callNumber,\n",
    "                    TorchWrapper.CallRecordKey.ResultKey.START_TIMESTAMP: call[TorchWrapper.CallRecordKey.ResultKey.START_TIMESTAMP],\n",
    "                    TorchWrapper.CallRecordKey.ResultKey.COST_TIME: call[TorchWrapper.CallRecordKey.ResultKey.COST_TIME],\n",
    "                    TorchWrapper.CallRecordKey.ResultKey.ARGUMENTS: call[TorchWrapper.CallRecordKey.ResultKey.ARGUMENTS]\n",
    "                };\n",
    "                records.append(record);\n",
    "        return pd.DataFrame(records);\n",
    "\n",
    "    def saveRecords(self, config: dict):\n",
    "        \"\"\"\n",
    "        Save the call records to a file based on the configuration.\n",
    "        \n",
    "        **params**\n",
    "        config (dict): The configuration dictionary.\n",
    "        \"\"\"\n",
    "        def saveToJson(data: pd.DataFrame, path: str, fileName: str):\n",
    "            data.to_json(f\"{path}/{fileName}.json\", orient='records', lines=True);\n",
    "            return f\"{path}/{fileName}.json\";\n",
    "\n",
    "        def saveToCSV(data: pd.DataFrame, path: str, fileName: str):\n",
    "            data.to_csv(f\"{path}/{fileName}.csv\", index=False);\n",
    "\n",
    "        def saveToExcel(data: pd.DataFrame, path: str, fileName: str):\n",
    "            data.to_excel(f\"{path}/{fileName}.xlsx\", index=False);\n",
    "\n",
    "        def saveToHTML(data: pd.DataFrame, path: str, fileName: str):\n",
    "            data.to_html(f\"{path}/{fileName}.html\", index=False);\n",
    "\n",
    "        fileName = self.getFileName(config);\n",
    "        data = self.getDFFormattedCallRecords();\n",
    "        outputPath = self.setPath(config[TorchWrapper.ConfigKey.OUT_DIR]);\n",
    "        if config[TorchWrapper.ConfigKey.FORMAT] == \"json\":\n",
    "            saveToJson(data, outputPath, fileName);\n",
    "            return f\"{outputPath}/{fileName}.json\";\n",
    "        elif config[TorchWrapper.ConfigKey.FORMAT] == \"csv\":\n",
    "            saveToCSV(data, outputPath, fileName);\n",
    "            return f\"{outputPath}/{fileName}.csv\";\n",
    "        elif config[TorchWrapper.ConfigKey.FORMAT] == \"xlsx\":\n",
    "            saveToExcel(data, outputPath, fileName);\n",
    "            return f\"{outputPath}/{fileName}.xlsx\";\n",
    "        elif config[TorchWrapper.ConfigKey.FORMAT] == \"html\":\n",
    "            saveToHTML(data, outputPath, fileName);\n",
    "            return f\"{path}/{fileName}.html\";\n",
    "            \n",
    "    \"\"\"\n",
    "    **************\n",
    "    Usable Section\n",
    "    **************\n",
    "    \"\"\"\n",
    "\n",
    "    def start(self, func: types.FunctionType):\n",
    "        \"\"\"\n",
    "        Starts the wrapping and recording process.\n",
    "        \n",
    "        **params**\n",
    "        func (types.FunctionType): The function to be executed and recorded.\n",
    "        \n",
    "        **returns**\n",
    "        Any: The result of the executed function.\n",
    "        callRecords: the DataFrameFormatted callRecords.\n",
    "        \n",
    "        **raises**\n",
    "        ValueError: If there is an error executing the goal function.\n",
    "        \"\"\"\n",
    "        \n",
    "        # decorate the module to be evaluated\n",
    "        print(f\"Starts decorating torch module.\");\n",
    "        self.decorateModule(torch);\n",
    "        print(\"torch module decorating complete.\");\n",
    "        \n",
    "        # run the codes to be evaluated.\n",
    "        try:\n",
    "            print(f\"Starts evaluating {func.__name__}\");\n",
    "            result = func();\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error executing the function: {e}\");\n",
    "            raise ValueError(\"Error executing the function, check your code first.\") from e;\n",
    "            \n",
    "        # saving the results\n",
    "        print(\"start saving results.\");\n",
    "        path = self.saveRecords(self.config);\n",
    "        print(f\"results file saved to `{path}`\");\n",
    "        return result, self.getDFFormattedCallRecords();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab08d352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your wrapper config: {'out_dir': './output', 'file_max_size': '10MB', 'file_name_spec': 'timestamp', 'format': 'csv'}\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"out_dir\": \"./output\",\n",
    "    \"file_max_size\": \"10MB\",\n",
    "    \"file_name_spec\": \"timestamp\"\n",
    "};\n",
    "wrapper = TorchWrapper(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f72e17f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myCode():\n",
    "    a = torch.randn(1, 3);\n",
    "    b = torch.randn(1, 3);\n",
    "    c = a + b;\n",
    "    return c;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "570d3592",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your wrapper config: {'out_dir': './output', 'format': 'csv', 'file_max_size': '10MB', 'file_name_spec': 'timestamp'}\n",
      "Starts decorating torch module.\n",
      "[EXTATTR]`math` is a external attribute, not inside `torch`, out.\n",
      "[EXTATTR]`os` is a external attribute, not inside `torch`, out.\n",
      "[EXTATTR]`sys` is a external attribute, not inside `torch`, out.\n",
      "[EXTATTR]`platform` is a external attribute, not inside `torch`, out.\n",
      "[EXTATTR]`textwrap` is a external attribute, not inside `torch`, out.\n",
      "[EXTATTR]`ctypes` is a external attribute, not inside `torch`, out.\n",
      "[EXTATTR]`inspect` is a external attribute, not inside `torch`, out.\n",
      "\t[Operator]Operator `torch._running_with_deploy` hasn't been decorated, \n",
      "\tdecorating _running_with_deploy.\n",
      "\t[SubModule]Submodule `_utils` of torch hasn't been decorated, \n",
      "\tdecorating _utils.\n",
      "[EXTATTR]`copyreg` is a external attribute, not inside `torch`, out.\n",
      "[EXTATTR]`functools` is a external attribute, not inside `torch`, out.\n",
      "[EXTATTR]`sys` is a external attribute, not inside `torch`, out.\n",
      "[EXTATTR]`traceback` is a external attribute, not inside `torch`, out.\n",
      "[EXTATTR]`warnings` is a external attribute, not inside `torch`, out.\n",
      "[EXTATTR]`collections.defaultdict` is a external attribute, not inside `torch`, out.\n",
      "[EXTATTR]`typing.Any` is a external attribute, not inside `torch`, out.\n",
      "[EXTATTR]`typing.DefaultDict` is a external attribute, not inside `torch`, out.\n",
      "[EXTATTR]`typing.List` is a external attribute, not inside `torch`, out.\n",
      "[EXTATTR]`typing.Optional` is a external attribute, not inside `torch`, out.\n",
      "\t[SubModule]Submodule `torch` of torch._utils hasn't been decorated, \n",
      "\tdecorating torch.\n",
      "\t[SubModule]Submodule `torch` has been decorated.\n",
      "\t[Operator]Operator `torch._utils._type` hasn't been decorated, \n",
      "\tdecorating _type.\n",
      "\t[Operator]Operator `torch._utils._hpu` hasn't been decorated, \n",
      "\tdecorating _hpu.\n",
      "\t[Operator]Operator `torch._utils._cuda` hasn't been decorated, \n",
      "\tdecorating _cuda.\n",
      "\t[Operator]Operator `torch._utils._get_async_or_non_blocking` hasn't been decorated, \n",
      "\tdecorating _get_async_or_non_blocking.\n",
      "\t[Operator]Operator `torch._utils._rebuild_tensor` hasn't been decorated, \n",
      "\tdecorating _rebuild_tensor.\n",
      "\t[Operator]Operator `torch._utils.get_tensor_metadata` hasn't been decorated, \n",
      "\tdecorating get_tensor_metadata.\n",
      "\t[Operator]Operator `torch._utils.set_tensor_metadata` hasn't been decorated, \n",
      "\tdecorating set_tensor_metadata.\n",
      "\t[Operator]Operator `torch._utils._rebuild_tensor_v2` hasn't been decorated, \n",
      "\tdecorating _rebuild_tensor_v2.\n",
      "\t[Operator]Operator `torch._utils._validate_loaded_sparse_tensors` hasn't been decorated, \n",
      "\tdecorating _validate_loaded_sparse_tensors.\n",
      "\t[Operator]Operator `torch._utils._rebuild_sparse_tensor` hasn't been decorated, \n",
      "\tdecorating _rebuild_sparse_tensor.\n",
      "\t[Operator]Operator `torch._utils._rebuild_device_tensor_from_numpy` hasn't been decorated, \n",
      "\tdecorating _rebuild_device_tensor_from_numpy.\n",
      "\t[Operator]Operator `torch._utils._rebuild_device_tensor_from_numpy` hasn't been decorated, \n",
      "\tdecorating _rebuild_xla_tensor.\n",
      "\t[Operator]Operator `torch._utils._rebuild_meta_tensor_no_storage` hasn't been decorated, \n",
      "\tdecorating _rebuild_meta_tensor_no_storage.\n",
      "\t[Operator]Operator `torch._utils._rebuild_wrapper_subclass` hasn't been decorated, \n",
      "\tdecorating _rebuild_wrapper_subclass.\n",
      "\t[Operator]Operator `torch._utils._rebuild_qtensor` hasn't been decorated, \n",
      "\tdecorating _rebuild_qtensor.\n",
      "\t[Operator]Operator `torch._utils._rebuild_parameter` hasn't been decorated, \n",
      "\tdecorating _rebuild_parameter.\n",
      "\t[Operator]Operator `torch._utils._rebuild_parameter_with_state` hasn't been decorated, \n",
      "\tdecorating _rebuild_parameter_with_state.\n",
      "\t[Operator]Operator `torch._utils._get_obj_state` hasn't been decorated, \n",
      "\tdecorating _get_obj_state.\n",
      "\t[Operator]Operator `torch._utils._set_obj_state` hasn't been decorated, \n",
      "\tdecorating _set_obj_state.\n",
      "\t[Operator]Operator `torch._utils._import_dotted_name` hasn't been decorated, \n",
      "\tdecorating _import_dotted_name.\n",
      "\t[Operator]Operator `torch._utils._accumulate` hasn't been decorated, \n",
      "\tdecorating _accumulate.\n",
      "\t[Operator]Operator `torch._utils._flatten_dense_tensors` hasn't been decorated, \n",
      "\tdecorating _flatten_dense_tensors.\n",
      "\t[Operator]Operator `torch._utils._flatten_sparse_tensors` hasn't been decorated, \n",
      "\tdecorating _flatten_sparse_tensors.\n",
      "\t[Operator]Operator `torch._utils._unflatten_dense_tensors` hasn't been decorated, \n",
      "\tdecorating _unflatten_dense_tensors.\n",
      "\t[Operator]Operator `torch._utils._unflatten_sparse_tensors` hasn't been decorated, \n",
      "\tdecorating _unflatten_sparse_tensors.\n",
      "\t[Operator]Operator `torch._utils._reorder_tensors_as` hasn't been decorated, \n",
      "\tdecorating _reorder_tensors_as.\n",
      "\t[Operator]Operator `torch._utils._take_tensors` hasn't been decorated, \n",
      "\tdecorating _take_tensors.\n",
      "\t[Operator]Operator `torch._utils.annotate` hasn't been decorated, \n",
      "\tdecorating annotate.\n",
      "\t[Operator]Operator `torch._utils.render_call` hasn't been decorated, \n",
      "\tdecorating render_call.\n",
      "\t[SubClass]SubClass `KeyErrorMessage` of torch._utils hasn't been decorated, \n",
      "\tdecorating torch._utils.KeyErrorMessage.\n",
      "\t[Class] Class `torch._utils.KeyErrorMessage` is not decorated, decorate it.\n",
      "\t[SubClass]SubClass `ExceptionWrapper` of torch._utils hasn't been decorated, \n",
      "\tdecorating torch._utils.ExceptionWrapper.\n",
      "\t[Class] Class `torch._utils.ExceptionWrapper` is not decorated, decorate it.\n",
      "\t\t[Method] Method `reraise` hasn't been decorated, \n",
      "\t\tdecorating `reraise`.\n",
      "\t\tMethod `reraise` has been decorated.\n",
      "\t[SubClass]SubClass `ExceptionWrapper` has been decorated.\n",
      "\t[Operator]Operator `torch._utils._get_available_device_type` hasn't been decorated, \n",
      "\tdecorating _get_available_device_type.\n",
      "\t[Operator]Operator `torch._utils._get_device_attr` hasn't been decorated, \n",
      "\tdecorating _get_device_attr.\n",
      "\t[Operator]Operator `torch._utils._get_current_device_index` hasn't been decorated, \n",
      "\tdecorating _get_current_device_index.\n",
      "\t[Operator]Operator `torch._utils._get_all_device_indices` hasn't been decorated, \n",
      "\tdecorating _get_all_device_indices.\n",
      "\t[Operator]Operator `torch._utils._get_devices_properties` hasn't been decorated, \n",
      "\tdecorating _get_devices_properties.\n",
      "\t[Operator]Operator `torch._utils.get_current_device_index` hasn't been decorated, \n",
      "\tdecorating get_current_device_index.\n",
      "\t[Operator]Operator `torch._utils._get_device_index` hasn't been decorated, \n",
      "\tdecorating _get_device_index.\n",
      "\t[Operator]Operator `torch._utils._handle_complex` hasn't been decorated, \n",
      "\tdecorating _handle_complex.\n",
      "\t[Operator]Operator `torch._utils._element_size` hasn't been decorated, \n",
      "\tdecorating _element_size.\n",
      "\t[SubClass]SubClass `_ClassPropertyDescriptor` of torch._utils hasn't been decorated, \n",
      "\tdecorating torch._utils._ClassPropertyDescriptor.\n",
      "\t[Class] Class `torch._utils._ClassPropertyDescriptor` is not decorated, decorate it.\n",
      "\t[Operator]Operator `torch._utils.classproperty` hasn't been decorated, \n",
      "\tdecorating classproperty.\n",
      "\t[Operator]Operator `torch._utils.is_compiling` hasn't been decorated, \n",
      "\tdecorating is_compiling.\n",
      "[EXTATTR]`<class 'functools._lru_cache_wrapper'>` is a external attribute, not inside `torch`, out.\n",
      "\t[SubModule]Submodule `_utils` has been decorated.\n",
      "\t[Operator]Operator `torch._utils._import_dotted_name` hasn't been decorated, \n",
      "\tdecorating _import_dotted_name.\n",
      "\t[Operator]Operator `torch._utils.classproperty` hasn't been decorated, \n",
      "\tdecorating classproperty.\n",
      "\t[SubModule]Submodule `_utils_internal` of torch hasn't been decorated, \n",
      "\tdecorating _utils_internal.\n",
      "[EXTATTR]`logging` is a external attribute, not inside `torch`, out.\n",
      "[EXTATTR]`os` is a external attribute, not inside `torch`, out.\n",
      "[EXTATTR]`tempfile` is a external attribute, not inside `torch`, out.\n",
      "[EXTATTR]`typing.Any` is a external attribute, not inside `torch`, out.\n",
      "[EXTATTR]`typing.Dict` is a external attribute, not inside `torch`, out.\n",
      "\t[SubModule]Submodule `torch` of torch._utils_internal hasn't been decorated, \n",
      "\tdecorating torch.\n",
      "\t[SubModule]Submodule `torch` has been decorated.\n",
      "\t[Operator]Operator `torch._utils_internal.get_file_path` hasn't been decorated, \n",
      "\tdecorating get_file_path.\n",
      "\t[Operator]Operator `torch._utils_internal.get_file_path_2` hasn't been decorated, \n",
      "\tdecorating get_file_path_2.\n",
      "\t[Operator]Operator `torch._utils_internal.get_writable_path` hasn't been decorated, \n",
      "\tdecorating get_writable_path.\n",
      "\t[Operator]Operator `torch._utils_internal.prepare_multiprocessing_environment` hasn't been decorated, \n",
      "\tdecorating prepare_multiprocessing_environment.\n",
      "\t[Operator]Operator `torch._utils_internal.resolve_library_path` hasn't been decorated, \n",
      "\tdecorating resolve_library_path.\n",
      "\t[Operator]Operator `torch._utils_internal.signpost_event` hasn't been decorated, \n",
      "\tdecorating signpost_event.\n",
      "\t[Operator]Operator `torch._utils_internal.log_compilation_event` hasn't been decorated, \n",
      "\tdecorating log_compilation_event.\n",
      "\t[SubModule]Submodule `_utils_internal` has been decorated.\n",
      "\t[Operator]Operator `torch._utils_internal.get_file_path` hasn't been decorated, \n",
      "\tdecorating get_file_path.\n",
      "\t[Operator]Operator `torch._utils_internal.prepare_multiprocessing_environment` hasn't been decorated, \n",
      "\tdecorating prepare_multiprocessing_environment.\n",
      "\t[SubModule]Submodule `version` of torch hasn't been decorated, \n",
      "\tdecorating version.\n",
      "\t[SubModule]Submodule `version` has been decorated.\n",
      "\t[SubModule]Submodule `torch_version` of torch hasn't been decorated, \n",
      "\tdecorating torch_version.\n",
      "[EXTATTR]`typing.Any` is a external attribute, not inside `torch`, out.\n",
      "[EXTATTR]`typing.Iterable` is a external attribute, not inside `torch`, out.\n",
      "\t[SubClass]SubClass `_LazyImport` of torch.torch_version hasn't been decorated, \n",
      "\tdecorating torch.torch_version._LazyImport.\n",
      "\t[Class] Class `torch.torch_version._LazyImport` is not decorated, decorate it.\n",
      "\t\t[Method] Method `get_cls` hasn't been decorated, \n",
      "\t\tdecorating `get_cls`.\n",
      "\t\tMethod `get_cls` has been decorated.\n",
      "\t[SubClass]SubClass `_LazyImport` has been decorated.\n",
      "\t[Decorated]Attribute `Version` of torch.torch_version has been decorated, out.\n",
      "\t[Decorated]Attribute `InvalidVersion` of torch.torch_version has been decorated, out.\n",
      "\t[SubClass]SubClass `TorchVersion` of torch.torch_version hasn't been decorated, \n",
      "\tdecorating torch.torch_version.TorchVersion.\n",
      "\t[Class] Class `torch.torch_version.TorchVersion` is not decorated, decorate it.\n",
      "\t\t[Method] Method `_convert_to_version` hasn't been decorated, \n",
      "\t\tdecorating `_convert_to_version`.\n",
      "\t\tMethod `_convert_to_version` has been decorated.\n",
      "\t\t[Method] Method `_cmp_wrapper` hasn't been decorated, \n",
      "\t\tdecorating `_cmp_wrapper`.\n",
      "\t\tMethod `_cmp_wrapper` has been decorated.\n",
      "\t[SubClass]SubClass `TorchVersion` has been decorated.\n",
      "\t[SubModule]Submodule `torch_version` has been decorated.\n",
      "[EXTATTR]`typing.Any` is a external attribute, not inside `torch`, out.\n",
      "[EXTATTR]`typing.Callable` is a external attribute, not inside `torch`, out.\n",
      "[EXTATTR]`typing.Dict` is a external attribute, not inside `torch`, out.\n",
      "[EXTATTR]`typing.Optional` is a external attribute, not inside `torch`, out.\n",
      "[EXTATTR]`typing.Set` is a external attribute, not inside `torch`, out.\n",
      "[EXTATTR]`typing.Tuple` is a external attribute, not inside `torch`, out.\n",
      "\t[SubClass]SubClass `Type` of torch hasn't been decorated, \n",
      "\tdecorating torch.Type.\n",
      "\t[Class] Class `torch.Type` is not decorated, decorate it.\n",
      "\t[SubClass]SubClass `Type` has been decorated.\n",
      "[EXTATTR]`typing.Union` is a external attribute, not inside `torch`, out.\n",
      "[EXTATTR]`typing.List` is a external attribute, not inside `torch`, out.\n",
      "[EXTATTR]`builtins` is a external attribute, not inside `torch`, out.\n",
      "[EXTATTR]`glob` is a external attribute, not inside `torch`, out.\n",
      "\t[Operator]Operator `torch._preload_cuda_deps` hasn't been decorated, \n",
      "\tdecorating _preload_cuda_deps.\n",
      "\t[Operator]Operator `torch._load_global_deps` hasn't been decorated, \n",
      "\tdecorating _load_global_deps.\n",
      "\t[SubModule]Submodule `_C` of torch hasn't been decorated, \n",
      "\tdecorating _C.\n",
      "\t[SkipDecoration]Attribute `_initExtension` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_autograd_init` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_add_docstr` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_init_names` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_has_distributed` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_set_default_tensor_type` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_set_default_dtype` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_infer_size` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_crash_if_csrc_asan` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_crash_if_csrc_ubsan` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_crash_if_vptr_ubsan` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_crash_if_aten_asan` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_crash_if_debug_asserts_fail` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_show_config` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cxx_flags` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_parallel_info` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_get_cpu_capability` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_set_backcompat_broadcast_warn` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_get_backcompat_broadcast_warn` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_set_backcompat_keepdim_warn` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_get_backcompat_keepdim_warn` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `get_num_threads` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `set_num_threads` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `get_num_interop_threads` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `set_num_interop_threads` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_get_flash_sdp_enabled` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_set_sdp_use_flash` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_get_mem_efficient_sdp_enabled` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_set_sdp_use_mem_efficient` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_get_math_sdp_enabled` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_set_sdp_use_math` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_get_cudnn_enabled` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_set_cudnn_enabled` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_get_mkldnn_enabled` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_set_mkldnn_enabled` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_get_cudnn_allow_tf32` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_set_cudnn_allow_tf32` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_get_cudnn_benchmark` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_set_cudnn_benchmark` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_get_cudnn_deterministic` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_set_cudnn_deterministic` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_get_deterministic_algorithms` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_get_deterministic_algorithms_warn_only` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_set_deterministic_algorithms` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_get_warnAlways` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_set_warnAlways` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_warn` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_warn_deprecation` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_get_cublas_allow_tf32` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_set_cublas_allow_tf32` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_get_float32_matmul_precision` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_set_float32_matmul_precision` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_get_cublas_allow_fp16_reduced_precision_reduction` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_set_cublas_allow_fp16_reduced_precision_reduction` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_get_cublas_allow_bf16_reduced_precision_reduction` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_set_cublas_allow_bf16_reduced_precision_reduction` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_vmapmode_increment_nesting` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_vmapmode_decrement_nesting` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_debug_only_display_vmap_fallback_warnings` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_debug_only_are_vmap_fallback_warnings_enabled` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_to_dlpack` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_from_dlpack` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_get_cpp_backtrace` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_rename_privateuse1_backend` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_get_privateuse1_backend_name` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `set_flush_denormal` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `get_default_dtype` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_get_default_device` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_get_qengine` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_set_qengine` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_supported_qengines` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_is_xnnpack_enabled` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_set_check_sparse_tensor_invariants` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_check_sparse_tensor_invariants` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_will_engine_execute_node` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_current_graph_task_execution_order` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_current_graph_task_id` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_current_autograd_node` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_set_default_mobile_cpu_allocator` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_unset_default_mobile_cpu_allocator` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_is_torch_function_enabled` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_disabled_torch_function_impl` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_disabled_torch_dispatch_impl` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_has_torch_function` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_has_torch_function_unary` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_has_torch_function_variadic` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_set_worker_signal_handlers` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_set_worker_pids` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_remove_worker_pids` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_error_if_any_worker_fails` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_set_grad_enabled` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `is_grad_enabled` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_set_fwd_grad_enabled` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_is_fwd_grad_enabled` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `is_inference_mode_enabled` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `set_autocast_enabled` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `is_autocast_enabled` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_is_any_autocast_enabled` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `clear_autocast_cache` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `set_autocast_cpu_enabled` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `is_autocast_cpu_enabled` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `set_autocast_cpu_dtype` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `get_autocast_cpu_dtype` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `set_autocast_gpu_dtype` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `get_autocast_gpu_dtype` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `set_autocast_xla_enabled` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `is_autocast_xla_enabled` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `set_autocast_xla_dtype` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `get_autocast_xla_dtype` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `set_autocast_ipu_enabled` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `is_autocast_ipu_enabled` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `set_autocast_ipu_dtype` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `get_autocast_ipu_dtype` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `autocast_increment_nesting` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `autocast_decrement_nesting` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `is_autocast_cache_enabled` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `set_autocast_cache_enabled` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_increment_version` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `set_anomaly_enabled` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `is_anomaly_enabled` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `is_anomaly_check_nan_enabled` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_is_multithreading_enabled` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_set_multithreading_enabled` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_is_view_replay_enabled` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_set_view_replay_enabled` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_enter_dual_level` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_exit_dual_level` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_is_torch_function_mode_enabled` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_push_on_torch_function_stack` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_pop_torch_function_stack` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_get_function_stack_at` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_len_torch_function_stack` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_push_on_torch_dispatch_stack` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_pop_torch_dispatch_stack` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_get_dispatch_stack_at` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_len_torch_dispatch_stack` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_multiprocessing_init` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_mps_deviceSynchronize` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_mps_is_in_bad_fork` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_mps_is_available` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_mps_is_on_macos_13_or_newer` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_mps_get_default_generator` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_mps_emptyCache` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_mps_setMemoryFraction` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_mps_currentAllocatedMemory` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_mps_driverAllocatedMemory` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_mps_profilerStartTrace` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_mps_profilerStopTrace` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_mps_acquireEvent` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_mps_releaseEvent` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_mps_recordEvent` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_mps_waitForEvent` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_mps_synchronizeEvent` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_mps_queryEvent` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_mps_elapsedTimeOfEvents` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_init` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_setDevice` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_exchangeDevice` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_maybeExchangeDevice` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_getDevice` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_getDeviceCount` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_canDeviceAccessPeer` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_getArchFlags` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_isInBadFork` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_getCurrentStream` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_getCurrentRawStream` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_getDefaultStream` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_getCurrentBlasHandle` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_clearCublasWorkspaces` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_isCurrentStreamCapturing` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_setStream` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_getCompiledVersion` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_hasPrimaryContext` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_setMemoryFraction` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_emptyCache` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_memoryStats` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_resetAccumulatedMemoryStats` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_resetPeakMemoryStats` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_memorySnapshot` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_attach_out_of_memory_observer` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_cudaHostAllocator` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_cudaCachingAllocator_raw_alloc` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_cudaCachingAllocator_raw_delete` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_cudaCachingAllocator_set_allocator_settings` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_getAllocatorBackend` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_synchronize` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_ipc_collect` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_sleep` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_lock_mutex` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_unlock_mutex` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_set_sync_debug_mode` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_get_sync_debug_mode` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_jiterator_compile_and_launch_kernel` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_get_cudnn_benchmark_limit` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_cuda_set_cudnn_benchmark_limit` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_rocm_is_backward_pass` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SkipDecoration]Attribute `_c10d_init` of torch._C skiped decoration, for unknow reason.\n",
      "\t[SubClass]SubClass `Generator` of torch._C hasn't been decorated, \n",
      "\tdecorating torch._C.Generator.\n",
      "\t[Class] Class `torch._C.Generator` is not decorated, decorate it.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "[decorateModule]The attribute that cause Error: `_C`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 163\u001b[0m, in \u001b[0;36mTorchWrapper.decorateClass\u001b[1;34m(self, cls)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_isDecorated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m;\n\u001b[0;32m    164\u001b[0m     cattr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, name);\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot set '_isDecorated' attribute of immutable type 'torch._C.Generator'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 216\u001b[0m, in \u001b[0;36mTorchWrapper.decorateModule\u001b[1;34m(self, module)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m[SubClass]SubClass `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmoduleName\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m hasn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt been decorated, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mdecorating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapiName\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m);\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecorateClass(mattr);\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isDecorated(mattr):\n",
      "Cell \u001b[1;32mIn[16], line 175\u001b[0m, in \u001b[0;36mTorchWrapper.decorateClass\u001b[1;34m(self, cls)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimmutable type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m[IMU]`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` is an immutable type, out.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m;\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m;\n",
      "\u001b[1;31mTypeError\u001b[0m: \t[IMU]`get_state` is an immutable type, out.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 206\u001b[0m, in \u001b[0;36mTorchWrapper.decorateModule\u001b[1;34m(self, module)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m[SubModule]Submodule `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmoduleName\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m hasn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt been decorated, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mdecorating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m);\n\u001b[1;32m--> 206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecorateModule(mattr);\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isDecorated(mattr):\n",
      "Cell \u001b[1;32mIn[16], line 226\u001b[0m, in \u001b[0;36mTorchWrapper.decorateModule\u001b[1;34m(self, module)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 226\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[decorateModule]The attribute that cause Error: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m;\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe attribute that cause Error: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m);\n",
      "\u001b[1;31mNameError\u001b[0m: [decorateModule]The attribute that cause Error: `Generator`",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./output\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_max_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m10MB\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_name_spec\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m };\n\u001b[0;32m      7\u001b[0m wrapper \u001b[38;5;241m=\u001b[39m TorchWrapper(config);\n\u001b[1;32m----> 9\u001b[0m wrapper\u001b[38;5;241m.\u001b[39mstart(myCode)\n",
      "Cell \u001b[1;32mIn[16], line 395\u001b[0m, in \u001b[0;36mTorchWrapper.start\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;66;03m# decorate the module to be evaluated\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarts decorating torch module.\u001b[39m\u001b[38;5;124m\"\u001b[39m);\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecorateModule(torch);\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch module decorating complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m);\n\u001b[0;32m    398\u001b[0m \u001b[38;5;66;03m# run the codes to be evaluated.\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[16], line 226\u001b[0m, in \u001b[0;36mTorchWrapper.decorateModule\u001b[1;34m(self, module)\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m[SkipDecoration]Attribute `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmoduleName\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m skiped decoration, for unknow reason.\u001b[39m\u001b[38;5;124m\"\u001b[39m);\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 226\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[decorateModule]The attribute that cause Error: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m;\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe attribute that cause Error: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m);\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m;\n",
      "\u001b[1;31mNameError\u001b[0m: [decorateModule]The attribute that cause Error: `_C`"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"out_dir\": \"./output\",\n",
    "    \"format\": \"csv\",\n",
    "    \"file_max_size\": \"10MB\",\n",
    "    \"file_name_spec\": \"timestamp\"\n",
    "};\n",
    "wrapper = TorchWrapper(config);\n",
    "\n",
    "wrapper.start(myCode);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41bea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ddd704",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(torch).index(\"_assert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c416927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dir(torch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8b676c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch._assert.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499231e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch._isDecorated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "611e4e43",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "math                                                                  math                                                             False\n",
      "os                                                                    os                                                               False\n",
      "sys                                                                   sys                                                              False\n",
      "platform                                                              platform                                                         False\n",
      "textwrap                                                              textwrap                                                         False\n",
      "ctypes                                                                ctypes                                                           False\n",
      "inspect                                                               inspect                                                          False\n",
      "torch._running_with_deploy                                            _running_with_deploy                                             True\n",
      "torch._utils                                                          _utils                                                           True\n",
      "torch._utils._import_dotted_name                                      _import_dotted_name                                              True\n",
      "torch._utils.classproperty                                            classproperty                                                    True\n",
      "torch._utils_internal                                                 _utils_internal                                                  True\n",
      "torch._utils_internal.get_file_path                                   get_file_path                                                    True\n",
      "torch._utils_internal.prepare_multiprocessing_environment             prepare_multiprocessing_environment                              True\n",
      "torch.version                                                         version                                                          True\n",
      "torch.torch_version                                                   torch_version                                                    True\n",
      "typing.Any                                                            Any                                                              False\n",
      "typing.Callable                                                       Callable                                                         False\n",
      "typing.Dict                                                           Dict                                                             False\n",
      "typing.Optional                                                       Optional                                                         False\n",
      "typing.Set                                                            Set                                                              False\n",
      "typing.Tuple                                                          Tuple                                                            False\n",
      "torch.Type                                                            Type                                                             True\n",
      "typing.Union                                                          Union                                                            False\n",
      "typing.List                                                           List                                                             False\n",
      "builtins                                                              builtins                                                         False\n",
      "glob                                                                  glob                                                             False\n",
      "torch._preload_cuda_deps                                              _preload_cuda_deps                                               True\n",
      "torch._load_global_deps                                               _load_global_deps                                                True\n",
      "torch._C                                                              _C                                                               True\n",
      "torch.get_num_threads                                                 get_num_threads                                                  True\n",
      "torch.set_num_threads                                                 set_num_threads                                                  True\n",
      "torch.get_num_interop_threads                                         get_num_interop_threads                                          True\n",
      "torch.set_num_interop_threads                                         set_num_interop_threads                                          True\n",
      "torch.set_flush_denormal                                              set_flush_denormal                                               True\n",
      "torch.get_default_dtype                                               get_default_dtype                                                True\n",
      "torch.is_grad_enabled                                                 is_grad_enabled                                                  True\n",
      "torch.is_inference_mode_enabled                                       is_inference_mode_enabled                                        True\n",
      "torch.set_autocast_enabled                                            set_autocast_enabled                                             True\n",
      "torch.is_autocast_enabled                                             is_autocast_enabled                                              True\n",
      "torch.clear_autocast_cache                                            clear_autocast_cache                                             True\n",
      "torch.set_autocast_cpu_enabled                                        set_autocast_cpu_enabled                                         True\n",
      "torch.is_autocast_cpu_enabled                                         is_autocast_cpu_enabled                                          True\n",
      "torch.set_autocast_cpu_dtype                                          set_autocast_cpu_dtype                                           True\n",
      "torch.get_autocast_cpu_dtype                                          get_autocast_cpu_dtype                                           True\n",
      "torch.set_autocast_gpu_dtype                                          set_autocast_gpu_dtype                                           True\n",
      "torch.get_autocast_gpu_dtype                                          get_autocast_gpu_dtype                                           True\n",
      "torch.set_autocast_xla_enabled                                        set_autocast_xla_enabled                                         True\n",
      "torch.is_autocast_xla_enabled                                         is_autocast_xla_enabled                                          True\n",
      "torch.set_autocast_xla_dtype                                          set_autocast_xla_dtype                                           True\n",
      "torch.get_autocast_xla_dtype                                          get_autocast_xla_dtype                                           True\n",
      "torch.set_autocast_ipu_enabled                                        set_autocast_ipu_enabled                                         True\n",
      "torch.is_autocast_ipu_enabled                                         is_autocast_ipu_enabled                                          True\n",
      "torch.set_autocast_ipu_dtype                                          set_autocast_ipu_dtype                                           True\n",
      "torch.get_autocast_ipu_dtype                                          get_autocast_ipu_dtype                                           True\n",
      "torch.autocast_increment_nesting                                      autocast_increment_nesting                                       True\n",
      "torch.autocast_decrement_nesting                                      autocast_decrement_nesting                                       True\n",
      "torch.is_autocast_cache_enabled                                       is_autocast_cache_enabled                                        True\n",
      "torch.set_autocast_cache_enabled                                      set_autocast_cache_enabled                                       True\n",
      "torch.set_anomaly_enabled                                             set_anomaly_enabled                                              True\n",
      "torch.is_anomaly_enabled                                              is_anomaly_enabled                                               True\n",
      "torch.is_anomaly_check_nan_enabled                                    is_anomaly_check_nan_enabled                                     True\n",
      "torch._C.Generator                                                    Generator                                                        True\n",
      "torch.FatalError                                                      FatalError                                                       True\n",
      "torch.Size                                                            Size                                                             True\n",
      "torch.dtype                                                           dtype                                                            True\n",
      "torch.finfo                                                           finfo                                                            True\n",
      "torch.iinfo                                                           iinfo                                                            True\n",
      "torch.layout                                                          layout                                                           True\n",
      "torch.memory_format                                                   memory_format                                                    True\n",
      "torch.qscheme                                                         qscheme                                                          True\n",
      "torch.device                                                          device                                                           True\n",
      "torch.Stream                                                          Stream                                                           True\n",
      "torch.Tag                                                             Tag                                                              True\n",
      "torch.jit.Error                                                       JITException                                                     True\n",
      "torch.IODescriptor                                                    IODescriptor                                                     True\n",
      "torch.CompleteArgumentSpec                                            CompleteArgumentSpec                                             True\n",
      "torch.ArgumentSpec                                                    ArgumentSpec                                                     True\n",
      "torch.Code                                                            Code                                                             True\n",
      "torch.ExecutionPlan                                                   ExecutionPlan                                                    True\n",
      "torch.Gradient                                                        Gradient                                                         True\n",
      "torch.GraphExecutorState                                              GraphExecutorState                                               True\n",
      "torch.PyTorchFileWriter                                               PyTorchFileWriter                                                True\n",
      "torch.PyTorchFileReader                                               PyTorchFileReader                                                True\n",
      "torch.DeserializationStorageContext                                   DeserializationStorageContext                                    True\n",
      "torch.parse_ir                                                        parse_ir                                                         True\n",
      "torch.parse_schema                                                    parse_schema                                                     True\n",
      "torch.unify_type_list                                                 unify_type_list                                                  True\n",
      "torch.FunctionSchema                                                  FunctionSchema                                                   True\n",
      "torch.Argument                                                        Argument                                                         True\n",
      "torch.Future                                                          Future                                                           True\n",
      "torch.fork                                                            fork                                                             True\n",
      "torch.wait                                                            wait                                                             True\n",
      "torch.ScriptClassFunction                                             ScriptClassFunction                                              True\n",
      "torch.ScriptClass                                                     ScriptClass                                                      True\n",
      "torch.AliasDb                                                         AliasDb                                                          True\n",
      "torch.Graph                                                           Graph                                                            True\n",
      "torch.Value                                                           Value                                                            True\n",
      "torch.Block                                                           Block                                                            True\n",
      "torch.Node                                                            Node                                                             True\n",
      "torch.AnyType                                                         AnyType                                                          True\n",
      "torch.NumberType                                                      NumberType                                                       True\n",
      "torch.IntType                                                         IntType                                                          True\n",
      "torch.SymIntType                                                      SymIntType                                                       True\n",
      "torch.SymBoolType                                                     SymBoolType                                                      True\n",
      "torch.FloatType                                                       FloatType                                                        True\n",
      "torch.ComplexType                                                     ComplexType                                                      True\n",
      "torch.TensorType                                                      TensorType                                                       True\n",
      "torch.BoolType                                                        BoolType                                                         True\n",
      "torch.StringType                                                      StringType                                                       True\n",
      "torch.DeviceObjType                                                   DeviceObjType                                                    True\n",
      "torch.StreamObjType                                                   StreamObjType                                                    True\n",
      "torch.PyObjectType                                                    PyObjectType                                                     True\n",
      "torch.NoneType                                                        NoneType                                                         True\n",
      "torch.TupleType                                                       TupleType                                                        True\n",
      "torch.UnionType                                                       UnionType                                                        True\n",
      "torch.ListType                                                        ListType                                                         True\n",
      "torch.DictType                                                        DictType                                                         True\n",
      "torch.OptionalType                                                    OptionalType                                                     True\n",
      "torch.RRefType                                                        RRefType                                                         True\n",
      "torch.FutureType                                                      FutureType                                                       True\n",
      "torch.AwaitType                                                       AwaitType                                                        True\n",
      "torch.ClassType                                                       ClassType                                                        True\n",
      "torch.EnumType                                                        EnumType                                                         True\n",
      "torch.InterfaceType                                                   InterfaceType                                                    True\n",
      "torch.InferredType                                                    InferredType                                                     True\n",
      "torch.Use                                                             Use                                                              True\n",
      "torch.TracingState                                                    TracingState                                                     True\n",
      "torch.Capsule                                                         Capsule                                                          True\n",
      "torch.ScriptObject                                                    ScriptObject                                                     True\n",
      "torch.ScriptObjectProperty                                            ScriptObjectProperty                                             True\n",
      "torch.DeepCopyMemoTable                                               DeepCopyMemoTable                                                True\n",
      "torch.ScriptModuleSerializer                                          ScriptModuleSerializer                                           True\n",
      "torch.SerializationStorageContext                                     SerializationStorageContext                                      True\n",
      "torch.ScriptModule                                                    ScriptModule                                                     True\n",
      "torch.LiteScriptModule                                                LiteScriptModule                                                 True\n",
      "torch.ParameterDict                                                   ParameterDict                                                    True\n",
      "torch.BufferDict                                                      BufferDict                                                       True\n",
      "torch.ModuleDict                                                      ModuleDict                                                       True\n",
      "torch.ErrorReport                                                     ErrorReport                                                      True\n",
      "torch.jit.CompilationUnit                                             CompilationUnit                                                  True\n",
      "torch.jit.ScriptFunction                                              ScriptFunction                                                   True\n",
      "torch.ScriptMethod                                                    ScriptMethod                                                     True\n",
      "torch.CallStack                                                       CallStack                                                        True\n",
      "torch.parse_type_comment                                              parse_type_comment                                               True\n",
      "torch.merge_type_from_type_comment                                    merge_type_from_type_comment                                     True\n",
      "torch.import_ir_module                                                import_ir_module                                                 True\n",
      "torch.import_ir_module_from_buffer                                    import_ir_module_from_buffer                                     True\n",
      "torch.OperatorInfo                                                    OperatorInfo                                                     True\n",
      "torch.FileCheck                                                       FileCheck                                                        True\n",
      "torch.ConcreteModuleTypeBuilder                                       ConcreteModuleTypeBuilder                                        True\n",
      "torch.ConcreteModuleType                                              ConcreteModuleType                                               True\n",
      "torch._C.LoggerBase                                                   LoggerBase                                                       True\n",
      "torch.AggregationType                                                 AggregationType                                                  True\n",
      "torch.LockingLogger                                                   LockingLogger                                                    True\n",
      "torch.NoopLogger                                                      NoopLogger                                                       True\n",
      "torch.ScriptDictKeyIterator                                           ScriptDictKeyIterator                                            True\n",
      "torch.ScriptDictIterator                                              ScriptDictIterator                                               True\n",
      "torch.ScriptDict                                                      ScriptDict                                                       True\n",
      "torch.ScriptListIterator                                              ScriptListIterator                                               True\n",
      "torch.ScriptList                                                      ScriptList                                                       True\n",
      "torch.StaticModule                                                    StaticModule                                                     True\n",
      "torch.DispatchKey                                                     DispatchKey                                                      True\n",
      "torch.DispatchKeySet                                                  DispatchKeySet                                                   True\n",
      "torch.ExcludeDispatchKeyGuard                                         ExcludeDispatchKeyGuard                                          True\n",
      "torch.BenchmarkConfig                                                 BenchmarkConfig                                                  True\n",
      "torch.BenchmarkExecutionStats                                         BenchmarkExecutionStats                                          True\n",
      "torch.ThroughputBenchmark                                             ThroughputBenchmark                                              True\n",
      "torch._C.cpp                                                          cpp                                                              True\n",
      "torch._C.StorageBase                                                  StorageBase                                                      True\n",
      "torch.vitals_enabled                                                  vitals_enabled                                                   True\n",
      "torch.set_vital                                                       set_vital                                                        True\n",
      "torch.read_vitals                                                     read_vitals                                                      True\n",
      "torch.init_num_threads                                                init_num_threads                                                 True\n",
      "torch._C.DisableTorchFunctionSubclass                                 DisableTorchFunctionSubclass                                     True\n",
      "torch._C.DisableTorchFunction                                         DisableTorchFunction                                             True\n",
      "torch.SymInt                                                          SymInt                                                           True\n",
      "torch.SymFloat                                                        SymFloat                                                         True\n",
      "torch.SymBool                                                         SymBool                                                          True\n",
      "torch.sym_not                                                         sym_not                                                          True\n",
      "torch.sym_float                                                       sym_float                                                        True\n",
      "torch.sym_int                                                         sym_int                                                          True\n",
      "torch.sym_max                                                         sym_max                                                          True\n",
      "torch.sym_min                                                         sym_min                                                          True\n",
      "torch._C._initExtension                                               _initExtension                                                   True\n",
      "torch.zeros_like                                                      obj                                                              True\n",
      "torch.wait                                                            candidate                                                        True\n",
      "torch.typename                                                        typename                                                         True\n",
      "torch.is_tensor                                                       is_tensor                                                        True\n",
      "torch.is_storage                                                      is_storage                                                       True\n",
      "torch.set_default_device                                              set_default_device                                               True\n",
      "torch.set_default_tensor_type                                         set_default_tensor_type                                          True\n",
      "torch.set_default_dtype                                               set_default_dtype                                                True\n",
      "torch.use_deterministic_algorithms                                    use_deterministic_algorithms                                     True\n",
      "torch.are_deterministic_algorithms_enabled                            are_deterministic_algorithms_enabled                             True\n",
      "torch.is_deterministic_algorithms_warn_only_enabled                   is_deterministic_algorithms_warn_only_enabled                    True\n",
      "torch.set_deterministic_debug_mode                                    set_deterministic_debug_mode                                     True\n",
      "torch.get_deterministic_debug_mode                                    get_deterministic_debug_mode                                     True\n",
      "torch.get_float32_matmul_precision                                    get_float32_matmul_precision                                     True\n",
      "torch.set_float32_matmul_precision                                    set_float32_matmul_precision                                     True\n",
      "torch.set_warn_always                                                 set_warn_always                                                  True\n",
      "torch.is_warn_always_enabled                                          is_warn_always_enabled                                           True\n",
      "torch._check_with                                                     _check_with                                                      True\n",
      "torch._check                                                          _check                                                           True\n",
      "torch._check_index                                                    _check_index                                                     True\n",
      "torch._check_value                                                    _check_value                                                     True\n",
      "torch._check_type                                                     _check_type                                                      True\n",
      "torch._check_not_implemented                                          _check_not_implemented                                           True\n",
      "torch._check_tensor_all_with                                          _check_tensor_all_with                                           True\n",
      "torch._check_tensor_all                                               _check_tensor_all                                                True\n",
      "torch.utils                                                           utils                                                            True\n",
      "torch._namedtensor_internals                                          _namedtensor_internals                                           True\n",
      "torch.overrides                                                       overrides                                                        True\n",
      "torch._tensor                                                         _tensor                                                          True\n",
      "torch.Tensor                                                          Tensor                                                           True\n",
      "torch.types                                                           types                                                            True\n",
      "torch.storage                                                         storage                                                          True\n",
      "torch.storage.TypedStorage                                            TypedStorage                                                     True\n",
      "torch.storage.UntypedStorage                                          UntypedStorage                                                   True\n",
      "torch.storage._warn_typed_storage_removal                             _warn_typed_storage_removal                                      True\n",
      "torch.ByteStorage                                                     ByteStorage                                                      True\n",
      "torch.DoubleStorage                                                   DoubleStorage                                                    True\n",
      "torch.FloatStorage                                                    FloatStorage                                                     True\n",
      "torch.HalfStorage                                                     HalfStorage                                                      True\n",
      "torch.LongStorage                                                     LongStorage                                                      True\n",
      "torch.IntStorage                                                      IntStorage                                                       True\n",
      "torch.ShortStorage                                                    ShortStorage                                                     True\n",
      "torch.CharStorage                                                     CharStorage                                                      True\n",
      "torch.BoolStorage                                                     BoolStorage                                                      True\n",
      "torch.BFloat16Storage                                                 BFloat16Storage                                                  True\n",
      "torch.ComplexDoubleStorage                                            ComplexDoubleStorage                                             True\n",
      "torch.ComplexFloatStorage                                             ComplexFloatStorage                                              True\n",
      "torch.QUInt8Storage                                                   QUInt8Storage                                                    True\n",
      "torch.QInt8Storage                                                    QInt8Storage                                                     True\n",
      "torch.QInt32Storage                                                   QInt32Storage                                                    True\n",
      "torch.QUInt4x2Storage                                                 QUInt4x2Storage                                                  True\n",
      "torch.QUInt2x4Storage                                                 QUInt2x4Storage                                                  True\n",
      "torch.random                                                          random                                                           True\n",
      "torch.random.set_rng_state                                            set_rng_state                                                    True\n",
      "torch.random.get_rng_state                                            get_rng_state                                                    True\n",
      "torch.random.manual_seed                                              manual_seed                                                      True\n",
      "torch.random.initial_seed                                             initial_seed                                                     True\n",
      "torch.random.seed                                                     seed                                                             True\n",
      "torch._sources                                                        _sources                                                         True\n",
      "torch._weights_only_unpickler                                         _weights_only_unpickler                                          True\n",
      "torch.serialization                                                   serialization                                                    True\n",
      "torch.serialization.save                                              save                                                             True\n",
      "torch.serialization.load                                              load                                                             True\n",
      "torch._tensor_str                                                     _tensor_str                                                      True\n",
      "torch._tensor_str.set_printoptions                                    set_printoptions                                                 True\n",
      "torch.amp                                                             amp                                                              True\n",
      "torch.amp.autocast_mode.autocast                                      autocast                                                         True\n",
      "builtins.float                                                        py_float                                                         False\n",
      "builtins.int                                                          py_int                                                           False\n",
      "torch.FloatStorage                                                    Storage                                                          True\n",
      "torch.ByteTensor                                                      ByteTensor                                                       True\n",
      "torch.CharTensor                                                      CharTensor                                                       True\n",
      "torch.DoubleTensor                                                    DoubleTensor                                                     True\n",
      "torch.FloatTensor                                                     FloatTensor                                                      True\n",
      "torch.IntTensor                                                       IntTensor                                                        True\n",
      "torch.LongTensor                                                      LongTensor                                                       True\n",
      "torch.ShortTensor                                                     ShortTensor                                                      True\n",
      "torch.HalfTensor                                                      HalfTensor                                                       True\n",
      "torch.BoolTensor                                                      BoolTensor                                                       True\n",
      "torch.BFloat16Tensor                                                  BFloat16Tensor                                                   True\n",
      "torch.cuda                                                            cuda                                                             True\n",
      "torch.sparse                                                          sparse                                                           True\n",
      "torch._adaptive_avg_pool2d                                            _adaptive_avg_pool2d                                             True\n",
      "torch._adaptive_avg_pool3d                                            _adaptive_avg_pool3d                                             True\n",
      "torch._add_batch_dim                                                  _add_batch_dim                                                   True\n",
      "torch._add_relu                                                       _add_relu                                                        True\n",
      "torch._add_relu_                                                      _add_relu_                                                       True\n",
      "torch._addmm_activation                                               _addmm_activation                                                True\n",
      "torch._aminmax                                                        _aminmax                                                         True\n",
      "torch._amp_foreach_non_finite_check_and_unscale_                      _amp_foreach_non_finite_check_and_unscale_                       True\n",
      "torch._amp_update_scale_                                              _amp_update_scale_                                               True\n",
      "torch._assert_async                                                   _assert_async                                                    True\n",
      "torch._assert_tensor_metadata                                         _assert_tensor_metadata                                          True\n",
      "torch._batch_norm_impl_index                                          _batch_norm_impl_index                                           True\n",
      "torch._cast_Byte                                                      _cast_Byte                                                       True\n",
      "torch._cast_Char                                                      _cast_Char                                                       True\n",
      "torch._cast_Double                                                    _cast_Double                                                     True\n",
      "torch._cast_Float                                                     _cast_Float                                                      True\n",
      "torch._cast_Half                                                      _cast_Half                                                       True\n",
      "torch._cast_Int                                                       _cast_Int                                                        True\n",
      "torch._cast_Long                                                      _cast_Long                                                       True\n",
      "torch._cast_Short                                                     _cast_Short                                                      True\n",
      "torch._choose_qparams_per_tensor                                      _choose_qparams_per_tensor                                       True\n",
      "torch._coalesce                                                       _coalesce                                                        True\n",
      "torch._compute_linear_combination                                     _compute_linear_combination                                      True\n",
      "torch._conj                                                           _conj                                                            True\n",
      "torch._conj_copy                                                      _conj_copy                                                       True\n",
      "torch._conj_physical                                                  _conj_physical                                                   True\n",
      "torch._convert_indices_from_coo_to_csr                                _convert_indices_from_coo_to_csr                                 True\n",
      "torch._convert_indices_from_csr_to_coo                                _convert_indices_from_csr_to_coo                                 True\n",
      "torch._convolution                                                    _convolution                                                     True\n",
      "torch._convolution_mode                                               _convolution_mode                                                True\n",
      "torch._copy_from                                                      _copy_from                                                       True\n",
      "torch._copy_from_and_resize                                           _copy_from_and_resize                                            True\n",
      "torch._cslt_compress                                                  _cslt_compress                                                   True\n",
      "torch._cslt_sparse_mm                                                 _cslt_sparse_mm                                                  True\n",
      "torch._ctc_loss                                                       _ctc_loss                                                        True\n",
      "torch._cudnn_ctc_loss                                                 _cudnn_ctc_loss                                                  True\n",
      "torch._cudnn_init_dropout_state                                       _cudnn_init_dropout_state                                        True\n",
      "torch._cudnn_rnn                                                      _cudnn_rnn                                                       True\n",
      "torch._cudnn_rnn_flatten_weight                                       _cudnn_rnn_flatten_weight                                        True\n",
      "torch._cufft_clear_plan_cache                                         _cufft_clear_plan_cache                                          True\n",
      "torch._cufft_get_plan_cache_max_size                                  _cufft_get_plan_cache_max_size                                   True\n",
      "torch._cufft_get_plan_cache_size                                      _cufft_get_plan_cache_size                                       True\n",
      "torch._cufft_set_plan_cache_max_size                                  _cufft_set_plan_cache_max_size                                   True\n",
      "torch._cummax_helper                                                  _cummax_helper                                                   True\n",
      "torch._cummin_helper                                                  _cummin_helper                                                   True\n",
      "torch._debug_has_internal_overlap                                     _debug_has_internal_overlap                                      True\n",
      "torch._dim_arange                                                     _dim_arange                                                      True\n",
      "torch._dirichlet_grad                                                 _dirichlet_grad                                                  True\n",
      "torch._disable_functionalization                                      _disable_functionalization                                       True\n",
      "torch._efficientzerotensor                                            _efficientzerotensor                                             True\n",
      "torch._embedding_bag                                                  _embedding_bag                                                   True\n",
      "torch._embedding_bag_forward_only                                     _embedding_bag_forward_only                                      True\n",
      "torch._empty_affine_quantized                                         _empty_affine_quantized                                          True\n",
      "torch._empty_per_channel_affine_quantized                             _empty_per_channel_affine_quantized                              True\n",
      "torch._enable_functionalization                                       _enable_functionalization                                        True\n",
      "torch._euclidean_dist                                                 _euclidean_dist                                                  True\n",
      "torch._fake_quantize_learnable_per_channel_affine                     _fake_quantize_learnable_per_channel_affine                      True\n",
      "torch._fake_quantize_learnable_per_tensor_affine                      _fake_quantize_learnable_per_tensor_affine                       True\n",
      "torch._fake_quantize_per_tensor_affine_cachemask_tensor_qparams       _fake_quantize_per_tensor_affine_cachemask_tensor_qparams        True\n",
      "torch._fft_c2c                                                        _fft_c2c                                                         True\n",
      "torch._fft_c2r                                                        _fft_c2r                                                         True\n",
      "torch._fft_r2c                                                        _fft_r2c                                                         True\n",
      "torch._fill_mem_eff_dropout_mask_                                     _fill_mem_eff_dropout_mask_                                      True\n",
      "torch._foobar                                                         _foobar                                                          True\n",
      "torch._foreach_abs                                                    _foreach_abs                                                     True\n",
      "torch._foreach_abs_                                                   _foreach_abs_                                                    True\n",
      "torch._foreach_acos                                                   _foreach_acos                                                    True\n",
      "torch._foreach_acos_                                                  _foreach_acos_                                                   True\n",
      "torch._foreach_add                                                    _foreach_add                                                     True\n",
      "torch._foreach_add_                                                   _foreach_add_                                                    True\n",
      "torch._foreach_addcdiv                                                _foreach_addcdiv                                                 True\n",
      "torch._foreach_addcdiv_                                               _foreach_addcdiv_                                                True\n",
      "torch._foreach_addcmul                                                _foreach_addcmul                                                 True\n",
      "torch._foreach_addcmul_                                               _foreach_addcmul_                                                True\n",
      "torch._foreach_asin                                                   _foreach_asin                                                    True\n",
      "torch._foreach_asin_                                                  _foreach_asin_                                                   True\n",
      "torch._foreach_atan                                                   _foreach_atan                                                    True\n",
      "torch._foreach_atan_                                                  _foreach_atan_                                                   True\n",
      "torch._foreach_ceil                                                   _foreach_ceil                                                    True\n",
      "torch._foreach_ceil_                                                  _foreach_ceil_                                                   True\n",
      "torch._foreach_clamp_max                                              _foreach_clamp_max                                               True\n",
      "torch._foreach_clamp_max_                                             _foreach_clamp_max_                                              True\n",
      "torch._foreach_clamp_min                                              _foreach_clamp_min                                               True\n",
      "torch._foreach_clamp_min_                                             _foreach_clamp_min_                                              True\n",
      "torch._foreach_copy_                                                  _foreach_copy_                                                   True\n",
      "torch._foreach_cos                                                    _foreach_cos                                                     True\n",
      "torch._foreach_cos_                                                   _foreach_cos_                                                    True\n",
      "torch._foreach_cosh                                                   _foreach_cosh                                                    True\n",
      "torch._foreach_cosh_                                                  _foreach_cosh_                                                   True\n",
      "torch._foreach_div                                                    _foreach_div                                                     True\n",
      "torch._foreach_div_                                                   _foreach_div_                                                    True\n",
      "torch._foreach_erf                                                    _foreach_erf                                                     True\n",
      "torch._foreach_erf_                                                   _foreach_erf_                                                    True\n",
      "torch._foreach_erfc                                                   _foreach_erfc                                                    True\n",
      "torch._foreach_erfc_                                                  _foreach_erfc_                                                   True\n",
      "torch._foreach_exp                                                    _foreach_exp                                                     True\n",
      "torch._foreach_exp_                                                   _foreach_exp_                                                    True\n",
      "torch._foreach_expm1                                                  _foreach_expm1                                                   True\n",
      "torch._foreach_expm1_                                                 _foreach_expm1_                                                  True\n",
      "torch._foreach_floor                                                  _foreach_floor                                                   True\n",
      "torch._foreach_floor_                                                 _foreach_floor_                                                  True\n",
      "torch._foreach_frac                                                   _foreach_frac                                                    True\n",
      "torch._foreach_frac_                                                  _foreach_frac_                                                   True\n",
      "torch._foreach_lerp                                                   _foreach_lerp                                                    True\n",
      "torch._foreach_lerp_                                                  _foreach_lerp_                                                   True\n",
      "torch._foreach_lgamma                                                 _foreach_lgamma                                                  True\n",
      "torch._foreach_lgamma_                                                _foreach_lgamma_                                                 True\n",
      "torch._foreach_log                                                    _foreach_log                                                     True\n",
      "torch._foreach_log10                                                  _foreach_log10                                                   True\n",
      "torch._foreach_log10_                                                 _foreach_log10_                                                  True\n",
      "torch._foreach_log1p                                                  _foreach_log1p                                                   True\n",
      "torch._foreach_log1p_                                                 _foreach_log1p_                                                  True\n",
      "torch._foreach_log2                                                   _foreach_log2                                                    True\n",
      "torch._foreach_log2_                                                  _foreach_log2_                                                   True\n",
      "torch._foreach_log_                                                   _foreach_log_                                                    True\n",
      "torch._foreach_maximum                                                _foreach_maximum                                                 True\n",
      "torch._foreach_maximum_                                               _foreach_maximum_                                                True\n",
      "torch._foreach_minimum                                                _foreach_minimum                                                 True\n",
      "torch._foreach_minimum_                                               _foreach_minimum_                                                True\n",
      "torch._foreach_mul                                                    _foreach_mul                                                     True\n",
      "torch._foreach_mul_                                                   _foreach_mul_                                                    True\n",
      "torch._foreach_neg                                                    _foreach_neg                                                     True\n",
      "torch._foreach_neg_                                                   _foreach_neg_                                                    True\n",
      "torch._foreach_norm                                                   _foreach_norm                                                    True\n",
      "torch._foreach_pow                                                    _foreach_pow                                                     True\n",
      "torch._foreach_pow_                                                   _foreach_pow_                                                    True\n",
      "torch._foreach_reciprocal                                             _foreach_reciprocal                                              True\n",
      "torch._foreach_reciprocal_                                            _foreach_reciprocal_                                             True\n",
      "torch._foreach_round                                                  _foreach_round                                                   True\n",
      "torch._foreach_round_                                                 _foreach_round_                                                  True\n",
      "torch._foreach_sigmoid                                                _foreach_sigmoid                                                 True\n",
      "torch._foreach_sigmoid_                                               _foreach_sigmoid_                                                True\n",
      "torch._foreach_sign                                                   _foreach_sign                                                    True\n",
      "torch._foreach_sign_                                                  _foreach_sign_                                                   True\n",
      "torch._foreach_sin                                                    _foreach_sin                                                     True\n",
      "torch._foreach_sin_                                                   _foreach_sin_                                                    True\n",
      "torch._foreach_sinh                                                   _foreach_sinh                                                    True\n",
      "torch._foreach_sinh_                                                  _foreach_sinh_                                                   True\n",
      "torch._foreach_sqrt                                                   _foreach_sqrt                                                    True\n",
      "torch._foreach_sqrt_                                                  _foreach_sqrt_                                                   True\n",
      "torch._foreach_sub                                                    _foreach_sub                                                     True\n",
      "torch._foreach_sub_                                                   _foreach_sub_                                                    True\n",
      "torch._foreach_tan                                                    _foreach_tan                                                     True\n",
      "torch._foreach_tan_                                                   _foreach_tan_                                                    True\n",
      "torch._foreach_tanh                                                   _foreach_tanh                                                    True\n",
      "torch._foreach_tanh_                                                  _foreach_tanh_                                                   True\n",
      "torch._foreach_trunc                                                  _foreach_trunc                                                   True\n",
      "torch._foreach_trunc_                                                 _foreach_trunc_                                                  True\n",
      "torch._foreach_zero_                                                  _foreach_zero_                                                   True\n",
      "torch._freeze_functional_tensor                                       _freeze_functional_tensor                                        True\n",
      "torch._from_functional_tensor                                         _from_functional_tensor                                          True\n",
      "torch._functional_assert_async                                        _functional_assert_async                                         True\n",
      "torch._functional_sym_constrain_range                                 _functional_sym_constrain_range                                  True\n",
      "torch._functional_sym_constrain_range_for_size                        _functional_sym_constrain_range_for_size                         True\n",
      "torch._functionalize_has_metadata_mutation                            _functionalize_has_metadata_mutation                             True\n",
      "torch._fused_adam_                                                    _fused_adam_                                                     True\n",
      "torch._fused_adamw_                                                   _fused_adamw_                                                    True\n",
      "torch._fused_dropout                                                  _fused_dropout                                                   True\n",
      "torch._fused_moving_avg_obs_fq_helper                                 _fused_moving_avg_obs_fq_helper                                  True\n",
      "torch._fused_sdp_choice                                               _fused_sdp_choice                                                True\n",
      "torch._fw_primal_copy                                                 _fw_primal_copy                                                  True\n",
      "torch._grid_sampler_2d_cpu_fallback                                   _grid_sampler_2d_cpu_fallback                                    True\n",
      "torch._has_compatible_shallow_copy_type                               _has_compatible_shallow_copy_type                                True\n",
      "torch._histogramdd_bin_edges                                          _histogramdd_bin_edges                                           True\n",
      "torch._histogramdd_from_bin_cts                                       _histogramdd_from_bin_cts                                        True\n",
      "torch._histogramdd_from_bin_tensors                                   _histogramdd_from_bin_tensors                                    True\n",
      "torch._index_put_impl_                                                _index_put_impl_                                                 True\n",
      "torch._indices_copy                                                   _indices_copy                                                    True\n",
      "torch._int_mm                                                         _int_mm                                                          True\n",
      "torch._is_all_true                                                    _is_all_true                                                     True\n",
      "torch._is_any_true                                                    _is_any_true                                                     True\n",
      "torch._is_functional_tensor                                           _is_functional_tensor                                            True\n",
      "torch._is_zerotensor                                                  _is_zerotensor                                                   True\n",
      "torch._linalg_check_errors                                            _linalg_check_errors                                             True\n",
      "torch._linalg_det                                                     _linalg_det                                                      True\n",
      "torch._linalg_eigh                                                    _linalg_eigh                                                     True\n",
      "torch._linalg_slogdet                                                 _linalg_slogdet                                                  True\n",
      "torch._linalg_solve_ex                                                _linalg_solve_ex                                                 True\n",
      "torch._linalg_svd                                                     _linalg_svd                                                      True\n",
      "torch._log_softmax                                                    _log_softmax                                                     True\n",
      "torch._log_softmax_backward_data                                      _log_softmax_backward_data                                       True\n",
      "torch._logcumsumexp                                                   _logcumsumexp                                                    True\n",
      "torch._lstm_mps                                                       _lstm_mps                                                        True\n",
      "torch._lu_with_info                                                   _lu_with_info                                                    True\n",
      "torch._make_dep_token                                                 _make_dep_token                                                  True\n",
      "torch._make_dual                                                      _make_dual                                                       True\n",
      "torch._make_dual_copy                                                 _make_dual_copy                                                  True\n",
      "torch._make_per_channel_quantized_tensor                              _make_per_channel_quantized_tensor                               True\n",
      "torch._make_per_tensor_quantized_tensor                               _make_per_tensor_quantized_tensor                                True\n",
      "torch._masked_scale                                                   _masked_scale                                                    True\n",
      "torch._masked_softmax                                                 _masked_softmax                                                  True\n",
      "torch._mkldnn_reshape                                                 _mkldnn_reshape                                                  True\n",
      "torch._mkldnn_transpose                                               _mkldnn_transpose                                                True\n",
      "torch._mkldnn_transpose_                                              _mkldnn_transpose_                                               True\n",
      "torch._mps_convolution                                                _mps_convolution                                                 True\n",
      "torch._mps_convolution_transpose                                      _mps_convolution_transpose                                       True\n",
      "torch._native_batch_norm_legit                                        _native_batch_norm_legit                                         True\n",
      "torch._native_batch_norm_legit_no_training                            _native_batch_norm_legit_no_training                             True\n",
      "torch._native_multi_head_attention                                    _native_multi_head_attention                                     True\n",
      "torch._neg_view                                                       _neg_view                                                        True\n",
      "torch._neg_view_copy                                                  _neg_view_copy                                                   True\n",
      "torch._nested_from_padded                                             _nested_from_padded                                              True\n",
      "torch._nested_from_padded_and_nested_example                          _nested_from_padded_and_nested_example                           True\n",
      "torch._nested_tensor_from_mask                                        _nested_tensor_from_mask                                         True\n",
      "torch._nested_tensor_from_mask_left_aligned                           _nested_tensor_from_mask_left_aligned                            True\n",
      "torch._nested_tensor_from_tensor_list                                 _nested_tensor_from_tensor_list                                  True\n",
      "torch._nested_tensor_softmax_with_shape                               _nested_tensor_softmax_with_shape                                True\n",
      "torch._nnpack_available                                               _nnpack_available                                                True\n",
      "torch._nnpack_spatial_convolution                                     _nnpack_spatial_convolution                                      True\n",
      "torch._pack_padded_sequence                                           _pack_padded_sequence                                            True\n",
      "torch._pad_packed_sequence                                            _pad_packed_sequence                                             True\n",
      "torch._pin_memory                                                     _pin_memory                                                      True\n",
      "torch._prelu_kernel                                                   _prelu_kernel                                                    True\n",
      "torch._propagate_xla_data                                             _propagate_xla_data                                              True\n",
      "torch._remove_batch_dim                                               _remove_batch_dim                                                True\n",
      "torch._reshape_alias_copy                                             _reshape_alias_copy                                              True\n",
      "torch._reshape_from_tensor                                            _reshape_from_tensor                                             True\n",
      "torch._resize_output_                                                 _resize_output_                                                  True\n",
      "torch._rowwise_prune                                                  _rowwise_prune                                                   True\n",
      "torch._sample_dirichlet                                               _sample_dirichlet                                                True\n",
      "torch._saturate_weight_to_fp16                                        _saturate_weight_to_fp16                                         True\n",
      "torch._scaled_dot_product_attention_math                              _scaled_dot_product_attention_math                               True\n",
      "torch._scaled_dot_product_efficient_attention                         _scaled_dot_product_efficient_attention                          True\n",
      "torch._scaled_dot_product_flash_attention                             _scaled_dot_product_flash_attention                              True\n",
      "torch._scaled_mm                                                      _scaled_mm                                                       True\n",
      "torch._shape_as_tensor                                                _shape_as_tensor                                                 True\n",
      "torch._sobol_engine_draw                                              _sobol_engine_draw                                               True\n",
      "torch._sobol_engine_ff_                                               _sobol_engine_ff_                                                True\n",
      "torch._sobol_engine_initialize_state_                                 _sobol_engine_initialize_state_                                  True\n",
      "torch._sobol_engine_scramble_                                         _sobol_engine_scramble_                                          True\n",
      "torch._softmax                                                        _softmax                                                         True\n",
      "torch._softmax_backward_data                                          _softmax_backward_data                                           True\n",
      "torch._sparse_broadcast_to                                            _sparse_broadcast_to                                             True\n",
      "torch._sparse_broadcast_to_copy                                       _sparse_broadcast_to_copy                                        True\n",
      "torch._sparse_csr_prod                                                _sparse_csr_prod                                                 True\n",
      "torch._sparse_csr_sum                                                 _sparse_csr_sum                                                  True\n",
      "torch._sparse_log_softmax_backward_data                               _sparse_log_softmax_backward_data                                True\n",
      "torch._sparse_semi_structured_linear                                  _sparse_semi_structured_linear                                   True\n",
      "torch._sparse_softmax_backward_data                                   _sparse_softmax_backward_data                                    True\n",
      "torch._sparse_sparse_matmul                                           _sparse_sparse_matmul                                            True\n",
      "torch._sparse_sum                                                     _sparse_sum                                                      True\n",
      "torch._stack                                                          _stack                                                           True\n",
      "torch._standard_gamma                                                 _standard_gamma                                                  True\n",
      "torch._standard_gamma_grad                                            _standard_gamma_grad                                             True\n",
      "torch._sync                                                           _sync                                                            True\n",
      "torch._test_autograd_multiple_dispatch                                _test_autograd_multiple_dispatch                                 True\n",
      "torch._test_autograd_multiple_dispatch_view                           _test_autograd_multiple_dispatch_view                            True\n",
      "torch._test_autograd_multiple_dispatch_view_copy                      _test_autograd_multiple_dispatch_view_copy                       True\n",
      "torch._test_check_tensor                                              _test_check_tensor                                               True\n",
      "torch._test_functorch_fallback                                        _test_functorch_fallback                                         True\n",
      "torch._test_serialization_subcmul                                     _test_serialization_subcmul                                      True\n",
      "torch._to_cpu                                                         _to_cpu                                                          True\n",
      "torch._to_functional_tensor                                           _to_functional_tensor                                            True\n",
      "torch._to_sparse_semi_structured                                      _to_sparse_semi_structured                                       True\n",
      "torch._transform_bias_rescale_qkv                                     _transform_bias_rescale_qkv                                      True\n",
      "torch._transformer_encoder_layer_fwd                                  _transformer_encoder_layer_fwd                                   True\n",
      "torch._trilinear                                                      _trilinear                                                       True\n",
      "torch._triton_multi_head_attention                                    _triton_multi_head_attention                                     True\n",
      "torch._triton_scaled_dot_attention                                    _triton_scaled_dot_attention                                     True\n",
      "torch._unique                                                         _unique                                                          True\n",
      "torch._unique2                                                        _unique2                                                         True\n",
      "torch._unpack_dual                                                    _unpack_dual                                                     True\n",
      "torch._unsafe_index                                                   _unsafe_index                                                    True\n",
      "torch._unsafe_index_put                                               _unsafe_index_put                                                True\n",
      "torch._use_cudnn_ctc_loss                                             _use_cudnn_ctc_loss                                              True\n",
      "torch._use_cudnn_rnn_flatten_weight                                   _use_cudnn_rnn_flatten_weight                                    True\n",
      "torch._validate_compressed_sparse_indices                             _validate_compressed_sparse_indices                              True\n",
      "torch._validate_sparse_bsc_tensor_args                                _validate_sparse_bsc_tensor_args                                 True\n",
      "torch._validate_sparse_bsr_tensor_args                                _validate_sparse_bsr_tensor_args                                 True\n",
      "torch._validate_sparse_compressed_tensor_args                         _validate_sparse_compressed_tensor_args                          True\n",
      "torch._validate_sparse_coo_tensor_args                                _validate_sparse_coo_tensor_args                                 True\n",
      "torch._validate_sparse_csc_tensor_args                                _validate_sparse_csc_tensor_args                                 True\n",
      "torch._validate_sparse_csr_tensor_args                                _validate_sparse_csr_tensor_args                                 True\n",
      "torch._values_copy                                                    _values_copy                                                     True\n",
      "torch._weight_norm                                                    _weight_norm                                                     True\n",
      "torch._weight_norm_interface                                          _weight_norm_interface                                           True\n",
      "torch.abs                                                             abs                                                              True\n",
      "torch.abs_                                                            abs_                                                             True\n",
      "torch.absolute                                                        absolute                                                         True\n",
      "torch.acos                                                            acos                                                             True\n",
      "torch.acos_                                                           acos_                                                            True\n",
      "torch.acosh                                                           acosh                                                            True\n",
      "torch.acosh_                                                          acosh_                                                           True\n",
      "torch.adaptive_avg_pool1d                                             adaptive_avg_pool1d                                              True\n",
      "torch.adaptive_max_pool1d                                             adaptive_max_pool1d                                              True\n",
      "torch.add                                                             add                                                              True\n",
      "torch.addbmm                                                          addbmm                                                           True\n",
      "torch.addcdiv                                                         addcdiv                                                          True\n",
      "torch.addcmul                                                         addcmul                                                          True\n",
      "torch.addmm                                                           addmm                                                            True\n",
      "torch.addmv                                                           addmv                                                            True\n",
      "torch.addmv_                                                          addmv_                                                           True\n",
      "torch.addr                                                            addr                                                             True\n",
      "torch.adjoint                                                         adjoint                                                          True\n",
      "torch.affine_grid_generator                                           affine_grid_generator                                            True\n",
      "torch.alias_copy                                                      alias_copy                                                       True\n",
      "torch.functional.align_tensors                                        align_tensors                                                    True\n",
      "torch.all                                                             all                                                              True\n",
      "torch.allclose                                                        allclose                                                         True\n",
      "torch.alpha_dropout                                                   alpha_dropout                                                    True\n",
      "torch.alpha_dropout_                                                  alpha_dropout_                                                   True\n",
      "torch.amax                                                            amax                                                             True\n",
      "torch.amin                                                            amin                                                             True\n",
      "torch.aminmax                                                         aminmax                                                          True\n",
      "torch.angle                                                           angle                                                            True\n",
      "torch.any                                                             any                                                              True\n",
      "torch.arange                                                          arange                                                           True\n",
      "torch.arccos                                                          arccos                                                           True\n",
      "torch.arccos_                                                         arccos_                                                          True\n",
      "torch.arccosh                                                         arccosh                                                          True\n",
      "torch.arccosh_                                                        arccosh_                                                         True\n",
      "torch.arcsin                                                          arcsin                                                           True\n",
      "torch.arcsin_                                                         arcsin_                                                          True\n",
      "torch.arcsinh                                                         arcsinh                                                          True\n",
      "torch.arcsinh_                                                        arcsinh_                                                         True\n",
      "torch.arctan                                                          arctan                                                           True\n",
      "torch.arctan2                                                         arctan2                                                          True\n",
      "torch.arctan_                                                         arctan_                                                          True\n",
      "torch.arctanh                                                         arctanh                                                          True\n",
      "torch.arctanh_                                                        arctanh_                                                         True\n",
      "torch.argmax                                                          argmax                                                           True\n",
      "torch.argmin                                                          argmin                                                           True\n",
      "torch.argsort                                                         argsort                                                          True\n",
      "torch.argwhere                                                        argwhere                                                         True\n",
      "torch.as_strided                                                      as_strided                                                       True\n",
      "torch.as_strided_                                                     as_strided_                                                      True\n",
      "torch.as_strided_copy                                                 as_strided_copy                                                  True\n",
      "torch.as_strided_scatter                                              as_strided_scatter                                               True\n",
      "torch.as_tensor                                                       as_tensor                                                        True\n",
      "torch.asarray                                                         asarray                                                          True\n",
      "torch.asin                                                            asin                                                             True\n",
      "torch.asin_                                                           asin_                                                            True\n",
      "torch.asinh                                                           asinh                                                            True\n",
      "torch.asinh_                                                          asinh_                                                           True\n",
      "torch.atan                                                            atan                                                             True\n",
      "torch.atan2                                                           atan2                                                            True\n",
      "torch.atan_                                                           atan_                                                            True\n",
      "torch.atanh                                                           atanh                                                            True\n",
      "torch.atanh_                                                          atanh_                                                           True\n",
      "torch.functional.atleast_1d                                           atleast_1d                                                       True\n",
      "torch.functional.atleast_2d                                           atleast_2d                                                       True\n",
      "torch.functional.atleast_3d                                           atleast_3d                                                       True\n",
      "torch.avg_pool1d                                                      avg_pool1d                                                       True\n",
      "torch.baddbmm                                                         baddbmm                                                          True\n",
      "torch.bartlett_window                                                 bartlett_window                                                  True\n",
      "torch.batch_norm                                                      batch_norm                                                       True\n",
      "torch.batch_norm_backward_elemt                                       batch_norm_backward_elemt                                        True\n",
      "torch.batch_norm_backward_reduce                                      batch_norm_backward_reduce                                       True\n",
      "torch.batch_norm_elemt                                                batch_norm_elemt                                                 True\n",
      "torch.batch_norm_gather_stats                                         batch_norm_gather_stats                                          True\n",
      "torch.batch_norm_gather_stats_with_counts                             batch_norm_gather_stats_with_counts                              True\n",
      "torch.batch_norm_stats                                                batch_norm_stats                                                 True\n",
      "torch.batch_norm_update_stats                                         batch_norm_update_stats                                          True\n",
      "torch.bernoulli                                                       bernoulli                                                        True\n",
      "torch.bilinear                                                        bilinear                                                         True\n",
      "torch.binary_cross_entropy_with_logits                                binary_cross_entropy_with_logits                                 True\n",
      "torch.bincount                                                        bincount                                                         True\n",
      "torch.binomial                                                        binomial                                                         True\n",
      "torch.bitwise_and                                                     bitwise_and                                                      True\n",
      "torch.bitwise_left_shift                                              bitwise_left_shift                                               True\n",
      "torch.bitwise_not                                                     bitwise_not                                                      True\n",
      "torch.bitwise_or                                                      bitwise_or                                                       True\n",
      "torch.bitwise_right_shift                                             bitwise_right_shift                                              True\n",
      "torch.bitwise_xor                                                     bitwise_xor                                                      True\n",
      "torch.blackman_window                                                 blackman_window                                                  True\n",
      "torch.functional.block_diag                                           block_diag                                                       True\n",
      "torch.bmm                                                             bmm                                                              True\n",
      "torch.functional.broadcast_tensors                                    broadcast_tensors                                                True\n",
      "torch.broadcast_to                                                    broadcast_to                                                     True\n",
      "torch.bucketize                                                       bucketize                                                        True\n",
      "torch.can_cast                                                        can_cast                                                         True\n",
      "torch.functional.cartesian_prod                                       cartesian_prod                                                   True\n",
      "torch.cat                                                             cat                                                              True\n",
      "torch.ccol_indices_copy                                               ccol_indices_copy                                                True\n",
      "torch.functional.cdist                                                cdist                                                            True\n",
      "torch.ceil                                                            ceil                                                             True\n",
      "torch.ceil_                                                           ceil_                                                            True\n",
      "torch.celu                                                            celu                                                             True\n",
      "torch.celu_                                                           celu_                                                            True\n",
      "torch.functional.chain_matmul                                         chain_matmul                                                     True\n",
      "torch.channel_shuffle                                                 channel_shuffle                                                  True\n",
      "torch.cholesky                                                        cholesky                                                         True\n",
      "torch.cholesky_inverse                                                cholesky_inverse                                                 True\n",
      "torch.cholesky_solve                                                  cholesky_solve                                                   True\n",
      "torch.choose_qparams_optimized                                        choose_qparams_optimized                                         True\n",
      "torch.chunk                                                           chunk                                                            True\n",
      "torch.clamp                                                           clamp                                                            True\n",
      "torch.clamp_                                                          clamp_                                                           True\n",
      "torch.clamp_max                                                       clamp_max                                                        True\n",
      "torch.clamp_max_                                                      clamp_max_                                                       True\n",
      "torch.clamp_min                                                       clamp_min                                                        True\n",
      "torch.clamp_min_                                                      clamp_min_                                                       True\n",
      "torch.clip                                                            clip                                                             True\n",
      "torch.clip_                                                           clip_                                                            True\n",
      "torch.clone                                                           clone                                                            True\n",
      "torch.col_indices_copy                                                col_indices_copy                                                 True\n",
      "torch.column_stack                                                    column_stack                                                     True\n",
      "torch.combinations                                                    combinations                                                     True\n",
      "torch.complex                                                         complex                                                          True\n",
      "torch.concat                                                          concat                                                           True\n",
      "torch.concatenate                                                     concatenate                                                      True\n",
      "torch.conj                                                            conj                                                             True\n",
      "torch.conj_physical                                                   conj_physical                                                    True\n",
      "torch.conj_physical_                                                  conj_physical_                                                   True\n",
      "torch.constant_pad_nd                                                 constant_pad_nd                                                  True\n",
      "torch.conv1d                                                          conv1d                                                           True\n",
      "torch.conv2d                                                          conv2d                                                           True\n",
      "torch.conv3d                                                          conv3d                                                           True\n",
      "torch.conv_tbc                                                        conv_tbc                                                         True\n",
      "torch.conv_transpose1d                                                conv_transpose1d                                                 True\n",
      "torch.conv_transpose2d                                                conv_transpose2d                                                 True\n",
      "torch.conv_transpose3d                                                conv_transpose3d                                                 True\n",
      "torch.convolution                                                     convolution                                                      True\n",
      "torch.copysign                                                        copysign                                                         True\n",
      "torch.corrcoef                                                        corrcoef                                                         True\n",
      "torch.cos                                                             cos                                                              True\n",
      "torch.cos_                                                            cos_                                                             True\n",
      "torch.cosh                                                            cosh                                                             True\n",
      "torch.cosh_                                                           cosh_                                                            True\n",
      "torch.cosine_embedding_loss                                           cosine_embedding_loss                                            True\n",
      "torch.cosine_similarity                                               cosine_similarity                                                True\n",
      "torch.count_nonzero                                                   count_nonzero                                                    True\n",
      "torch.cov                                                             cov                                                              True\n",
      "torch.cross                                                           cross                                                            True\n",
      "torch.crow_indices_copy                                               crow_indices_copy                                                True\n",
      "torch.ctc_loss                                                        ctc_loss                                                         True\n",
      "torch.cudnn_affine_grid_generator                                     cudnn_affine_grid_generator                                      True\n",
      "torch.cudnn_batch_norm                                                cudnn_batch_norm                                                 True\n",
      "torch.cudnn_convolution                                               cudnn_convolution                                                True\n",
      "torch.cudnn_convolution_add_relu                                      cudnn_convolution_add_relu                                       True\n",
      "torch.cudnn_convolution_relu                                          cudnn_convolution_relu                                           True\n",
      "torch.cudnn_convolution_transpose                                     cudnn_convolution_transpose                                      True\n",
      "torch.cudnn_grid_sampler                                              cudnn_grid_sampler                                               True\n",
      "torch.cudnn_is_acceptable                                             cudnn_is_acceptable                                              True\n",
      "torch.cummax                                                          cummax                                                           True\n",
      "torch.cummin                                                          cummin                                                           True\n",
      "torch.cumprod                                                         cumprod                                                          True\n",
      "torch.cumsum                                                          cumsum                                                           True\n",
      "torch.cumulative_trapezoid                                            cumulative_trapezoid                                             True\n",
      "torch.deg2rad                                                         deg2rad                                                          True\n",
      "torch.deg2rad_                                                        deg2rad_                                                         True\n",
      "torch.dequantize                                                      dequantize                                                       True\n",
      "torch.det                                                             det                                                              True\n",
      "torch.detach                                                          detach                                                           True\n",
      "torch.detach_                                                         detach_                                                          True\n",
      "torch.detach_copy                                                     detach_copy                                                      True\n",
      "torch.diag                                                            diag                                                             True\n",
      "torch.diag_embed                                                      diag_embed                                                       True\n",
      "torch.diagflat                                                        diagflat                                                         True\n",
      "torch.diagonal                                                        diagonal                                                         True\n",
      "torch.diagonal_copy                                                   diagonal_copy                                                    True\n",
      "torch.diagonal_scatter                                                diagonal_scatter                                                 True\n",
      "torch.diff                                                            diff                                                             True\n",
      "torch.digamma                                                         digamma                                                          True\n",
      "torch.dist                                                            dist                                                             True\n",
      "torch.div                                                             div                                                              True\n",
      "torch.divide                                                          divide                                                           True\n",
      "torch.dot                                                             dot                                                              True\n",
      "torch.dropout                                                         dropout                                                          True\n",
      "torch.dropout_                                                        dropout_                                                         True\n",
      "torch.dsmm                                                            dsmm                                                             True\n",
      "torch.dsplit                                                          dsplit                                                           True\n",
      "torch.dstack                                                          dstack                                                           True\n",
      "torch.functional.einsum                                               einsum                                                           True\n",
      "torch.embedding                                                       embedding                                                        True\n",
      "torch.embedding_bag                                                   embedding_bag                                                    True\n",
      "torch.embedding_renorm_                                               embedding_renorm_                                                True\n",
      "torch.empty                                                           empty                                                            True\n",
      "torch.empty_like                                                      empty_like                                                       True\n",
      "torch.empty_permuted                                                  empty_permuted                                                   True\n",
      "torch.empty_quantized                                                 empty_quantized                                                  True\n",
      "torch.empty_strided                                                   empty_strided                                                    True\n",
      "torch.eq                                                              eq                                                               True\n",
      "torch.equal                                                           equal                                                            True\n",
      "torch.erf                                                             erf                                                              True\n",
      "torch.erf_                                                            erf_                                                             True\n",
      "torch.erfc                                                            erfc                                                             True\n",
      "torch.erfc_                                                           erfc_                                                            True\n",
      "torch.erfinv                                                          erfinv                                                           True\n",
      "torch.exp                                                             exp                                                              True\n",
      "torch.exp2                                                            exp2                                                             True\n",
      "torch.exp2_                                                           exp2_                                                            True\n",
      "torch.exp_                                                            exp_                                                             True\n",
      "torch.expand_copy                                                     expand_copy                                                      True\n",
      "torch.expm1                                                           expm1                                                            True\n",
      "torch.expm1_                                                          expm1_                                                           True\n",
      "torch.eye                                                             eye                                                              True\n",
      "torch.fake_quantize_per_channel_affine                                fake_quantize_per_channel_affine                                 True\n",
      "torch.fake_quantize_per_tensor_affine                                 fake_quantize_per_tensor_affine                                  True\n",
      "torch.fbgemm_linear_fp16_weight                                       fbgemm_linear_fp16_weight                                        True\n",
      "torch.fbgemm_linear_fp16_weight_fp32_activation                       fbgemm_linear_fp16_weight_fp32_activation                        True\n",
      "torch.fbgemm_linear_int8_weight                                       fbgemm_linear_int8_weight                                        True\n",
      "torch.fbgemm_linear_int8_weight_fp32_activation                       fbgemm_linear_int8_weight_fp32_activation                        True\n",
      "torch.fbgemm_linear_quantize_weight                                   fbgemm_linear_quantize_weight                                    True\n",
      "torch.fbgemm_pack_gemm_matrix_fp16                                    fbgemm_pack_gemm_matrix_fp16                                     True\n",
      "torch.fbgemm_pack_quantized_matrix                                    fbgemm_pack_quantized_matrix                                     True\n",
      "torch.feature_alpha_dropout                                           feature_alpha_dropout                                            True\n",
      "torch.feature_alpha_dropout_                                          feature_alpha_dropout_                                           True\n",
      "torch.feature_dropout                                                 feature_dropout                                                  True\n",
      "torch.feature_dropout_                                                feature_dropout_                                                 True\n",
      "torch.fill                                                            fill                                                             True\n",
      "torch.fill_                                                           fill_                                                            True\n",
      "torch.fix                                                             fix                                                              True\n",
      "torch.fix_                                                            fix_                                                             True\n",
      "torch.flatten                                                         flatten                                                          True\n",
      "torch.flip                                                            flip                                                             True\n",
      "torch.fliplr                                                          fliplr                                                           True\n",
      "torch.flipud                                                          flipud                                                           True\n",
      "torch.float_power                                                     float_power                                                      True\n",
      "torch.floor                                                           floor                                                            True\n",
      "torch.floor_                                                          floor_                                                           True\n",
      "torch.floor_divide                                                    floor_divide                                                     True\n",
      "torch.fmax                                                            fmax                                                             True\n",
      "torch.fmin                                                            fmin                                                             True\n",
      "torch.fmod                                                            fmod                                                             True\n",
      "torch.frac                                                            frac                                                             True\n",
      "torch.frac_                                                           frac_                                                            True\n",
      "torch.frexp                                                           frexp                                                            True\n",
      "torch.frobenius_norm                                                  frobenius_norm                                                   True\n",
      "torch.from_file                                                       from_file                                                        True\n",
      "torch.from_numpy                                                      from_numpy                                                       True\n",
      "torch.frombuffer                                                      frombuffer                                                       True\n",
      "torch.full                                                            full                                                             True\n",
      "torch.full_like                                                       full_like                                                        True\n",
      "torch.fused_moving_avg_obs_fake_quant                                 fused_moving_avg_obs_fake_quant                                  True\n",
      "torch.gather                                                          gather                                                           True\n",
      "torch.gcd                                                             gcd                                                              True\n",
      "torch.gcd_                                                            gcd_                                                             True\n",
      "torch.ge                                                              ge                                                               True\n",
      "torch.geqrf                                                           geqrf                                                            True\n",
      "torch.ger                                                             ger                                                              True\n",
      "torch.get_device                                                      get_device                                                       True\n",
      "torch.gradient                                                        gradient                                                         True\n",
      "torch.greater                                                         greater                                                          True\n",
      "torch.greater_equal                                                   greater_equal                                                    True\n",
      "torch.grid_sampler                                                    grid_sampler                                                     True\n",
      "torch.grid_sampler_2d                                                 grid_sampler_2d                                                  True\n",
      "torch.grid_sampler_3d                                                 grid_sampler_3d                                                  True\n",
      "torch.group_norm                                                      group_norm                                                       True\n",
      "torch.gru                                                             gru                                                              True\n",
      "torch.gru_cell                                                        gru_cell                                                         True\n",
      "torch.gt                                                              gt                                                               True\n",
      "torch.hamming_window                                                  hamming_window                                                   True\n",
      "torch.hann_window                                                     hann_window                                                      True\n",
      "torch.hardshrink                                                      hardshrink                                                       True\n",
      "torch.heaviside                                                       heaviside                                                        True\n",
      "torch.hinge_embedding_loss                                            hinge_embedding_loss                                             True\n",
      "torch.histc                                                           histc                                                            True\n",
      "torch.histogram                                                       histogram                                                        True\n",
      "torch.histogramdd                                                     histogramdd                                                      True\n",
      "torch.hsmm                                                            hsmm                                                             True\n",
      "torch.hsplit                                                          hsplit                                                           True\n",
      "torch.hspmm                                                           hspmm                                                            True\n",
      "torch.hstack                                                          hstack                                                           True\n",
      "torch.hypot                                                           hypot                                                            True\n",
      "torch.i0                                                              i0                                                               True\n",
      "torch.i0_                                                             i0_                                                              True\n",
      "torch.igamma                                                          igamma                                                           True\n",
      "torch.igammac                                                         igammac                                                          True\n",
      "torch.imag                                                            imag                                                             True\n",
      "torch.index_add                                                       index_add                                                        True\n",
      "torch.index_copy                                                      index_copy                                                       True\n",
      "torch.index_fill                                                      index_fill                                                       True\n",
      "torch.index_put                                                       index_put                                                        True\n",
      "torch.index_put_                                                      index_put_                                                       True\n",
      "torch.index_reduce                                                    index_reduce                                                     True\n",
      "torch.index_select                                                    index_select                                                     True\n",
      "torch.indices_copy                                                    indices_copy                                                     True\n",
      "torch.inner                                                           inner                                                            True\n",
      "torch.instance_norm                                                   instance_norm                                                    True\n",
      "torch.int_repr                                                        int_repr                                                         True\n",
      "torch.inverse                                                         inverse                                                          True\n",
      "torch.is_complex                                                      is_complex                                                       True\n",
      "torch.is_conj                                                         is_conj                                                          True\n",
      "torch.is_distributed                                                  is_distributed                                                   True\n",
      "torch.is_floating_point                                               is_floating_point                                                True\n",
      "torch.is_inference                                                    is_inference                                                     True\n",
      "torch.is_neg                                                          is_neg                                                           True\n",
      "torch.is_nonzero                                                      is_nonzero                                                       True\n",
      "torch.is_same_size                                                    is_same_size                                                     True\n",
      "torch.is_signed                                                       is_signed                                                        True\n",
      "torch.is_vulkan_available                                             is_vulkan_available                                              True\n",
      "torch.isclose                                                         isclose                                                          True\n",
      "torch.isfinite                                                        isfinite                                                         True\n",
      "torch.isin                                                            isin                                                             True\n",
      "torch.isinf                                                           isinf                                                            True\n",
      "torch.isnan                                                           isnan                                                            True\n",
      "torch.isneginf                                                        isneginf                                                         True\n",
      "torch.isposinf                                                        isposinf                                                         True\n",
      "torch.isreal                                                          isreal                                                           True\n",
      "torch.istft                                                           istft                                                            True\n",
      "torch.kaiser_window                                                   kaiser_window                                                    True\n",
      "torch.kl_div                                                          kl_div                                                           True\n",
      "torch.kron                                                            kron                                                             True\n",
      "torch.kthvalue                                                        kthvalue                                                         True\n",
      "torch.layer_norm                                                      layer_norm                                                       True\n",
      "torch.lcm                                                             lcm                                                              True\n",
      "torch.lcm_                                                            lcm_                                                             True\n",
      "torch.ldexp                                                           ldexp                                                            True\n",
      "torch.ldexp_                                                          ldexp_                                                           True\n",
      "torch.le                                                              le                                                               True\n",
      "torch.lerp                                                            lerp                                                             True\n",
      "torch.less                                                            less                                                             True\n",
      "torch.less_equal                                                      less_equal                                                       True\n",
      "torch.lgamma                                                          lgamma                                                           True\n",
      "torch.linspace                                                        linspace                                                         True\n",
      "torch.log                                                             log                                                              True\n",
      "torch.log10                                                           log10                                                            True\n",
      "torch.log10_                                                          log10_                                                           True\n",
      "torch.log1p                                                           log1p                                                            True\n",
      "torch.log1p_                                                          log1p_                                                           True\n",
      "torch.log2                                                            log2                                                             True\n",
      "torch.log2_                                                           log2_                                                            True\n",
      "torch.log_                                                            log_                                                             True\n",
      "torch.log_softmax                                                     log_softmax                                                      True\n",
      "torch.logaddexp                                                       logaddexp                                                        True\n",
      "torch.logaddexp2                                                      logaddexp2                                                       True\n",
      "torch.logcumsumexp                                                    logcumsumexp                                                     True\n",
      "torch.logdet                                                          logdet                                                           True\n",
      "torch.logical_and                                                     logical_and                                                      True\n",
      "torch.logical_not                                                     logical_not                                                      True\n",
      "torch.logical_or                                                      logical_or                                                       True\n",
      "torch.logical_xor                                                     logical_xor                                                      True\n",
      "torch.logit                                                           logit                                                            True\n",
      "torch.logit_                                                          logit_                                                           True\n",
      "torch.logspace                                                        logspace                                                         True\n",
      "torch.logsumexp                                                       logsumexp                                                        True\n",
      "torch.lstm                                                            lstm                                                             True\n",
      "torch.lstm_cell                                                       lstm_cell                                                        True\n",
      "torch.lt                                                              lt                                                               True\n",
      "torch.lu_solve                                                        lu_solve                                                         True\n",
      "torch.lu_unpack                                                       lu_unpack                                                        True\n",
      "torch.margin_ranking_loss                                             margin_ranking_loss                                              True\n",
      "torch.masked_fill                                                     masked_fill                                                      True\n",
      "torch.masked_scatter                                                  masked_scatter                                                   True\n",
      "torch.masked_select                                                   masked_select                                                    True\n",
      "torch.matmul                                                          matmul                                                           True\n",
      "torch.matrix_exp                                                      matrix_exp                                                       True\n",
      "torch.matrix_power                                                    matrix_power                                                     True\n",
      "torch.max                                                             max                                                              True\n",
      "torch.max_pool1d                                                      max_pool1d                                                       True\n",
      "torch.max_pool1d_with_indices                                         max_pool1d_with_indices                                          True\n",
      "torch.max_pool2d                                                      max_pool2d                                                       True\n",
      "torch.max_pool3d                                                      max_pool3d                                                       True\n",
      "torch.maximum                                                         maximum                                                          True\n",
      "torch.mean                                                            mean                                                             True\n",
      "torch.median                                                          median                                                           True\n",
      "torch.functional.meshgrid                                             meshgrid                                                         True\n",
      "torch.min                                                             min                                                              True\n",
      "torch.minimum                                                         minimum                                                          True\n",
      "torch.miopen_batch_norm                                               miopen_batch_norm                                                True\n",
      "torch.miopen_convolution                                              miopen_convolution                                               True\n",
      "torch.miopen_convolution_add_relu                                     miopen_convolution_add_relu                                      True\n",
      "torch.miopen_convolution_relu                                         miopen_convolution_relu                                          True\n",
      "torch.miopen_convolution_transpose                                    miopen_convolution_transpose                                     True\n",
      "torch.miopen_depthwise_convolution                                    miopen_depthwise_convolution                                     True\n",
      "torch.miopen_rnn                                                      miopen_rnn                                                       True\n",
      "torch.mkldnn_adaptive_avg_pool2d                                      mkldnn_adaptive_avg_pool2d                                       True\n",
      "torch.mkldnn_convolution                                              mkldnn_convolution                                               True\n",
      "torch.mkldnn_linear_backward_weights                                  mkldnn_linear_backward_weights                                   True\n",
      "torch.mkldnn_max_pool2d                                               mkldnn_max_pool2d                                                True\n",
      "torch.mkldnn_max_pool3d                                               mkldnn_max_pool3d                                                True\n",
      "torch.mkldnn_rnn_layer                                                mkldnn_rnn_layer                                                 True\n",
      "torch.mm                                                              mm                                                               True\n",
      "torch.mode                                                            mode                                                             True\n",
      "torch.moveaxis                                                        moveaxis                                                         True\n",
      "torch.movedim                                                         movedim                                                          True\n",
      "torch.msort                                                           msort                                                            True\n",
      "torch.mul                                                             mul                                                              True\n",
      "torch.multinomial                                                     multinomial                                                      True\n",
      "torch.multiply                                                        multiply                                                         True\n",
      "torch.mv                                                              mv                                                               True\n",
      "torch.mvlgamma                                                        mvlgamma                                                         True\n",
      "torch.nan_to_num                                                      nan_to_num                                                       True\n",
      "torch.nan_to_num_                                                     nan_to_num_                                                      True\n",
      "torch.nanmean                                                         nanmean                                                          True\n",
      "torch.nanmedian                                                       nanmedian                                                        True\n",
      "torch.nanquantile                                                     nanquantile                                                      True\n",
      "torch.nansum                                                          nansum                                                           True\n",
      "torch.narrow                                                          narrow                                                           True\n",
      "torch.narrow_copy                                                     narrow_copy                                                      True\n",
      "torch.native_batch_norm                                               native_batch_norm                                                True\n",
      "torch.native_channel_shuffle                                          native_channel_shuffle                                           True\n",
      "torch.native_dropout                                                  native_dropout                                                   True\n",
      "torch.native_group_norm                                               native_group_norm                                                True\n",
      "torch.native_layer_norm                                               native_layer_norm                                                True\n",
      "torch.native_norm                                                     native_norm                                                      True\n",
      "torch.ne                                                              ne                                                               True\n",
      "torch.neg                                                             neg                                                              True\n",
      "torch.neg_                                                            neg_                                                             True\n",
      "torch.negative                                                        negative                                                         True\n",
      "torch.negative_                                                       negative_                                                        True\n",
      "torch.nextafter                                                       nextafter                                                        True\n",
      "torch.nonzero                                                         nonzero                                                          True\n",
      "torch.nonzero_static                                                  nonzero_static                                                   True\n",
      "torch.functional.norm                                                 norm                                                             True\n",
      "torch.norm_except_dim                                                 norm_except_dim                                                  True\n",
      "torch.normal                                                          normal                                                           True\n",
      "torch.not_equal                                                       not_equal                                                        True\n",
      "torch.nuclear_norm                                                    nuclear_norm                                                     True\n",
      "torch.numel                                                           numel                                                            True\n",
      "torch.ones                                                            ones                                                             True\n",
      "torch.ones_like                                                       ones_like                                                        True\n",
      "torch.orgqr                                                           orgqr                                                            True\n",
      "torch.ormqr                                                           ormqr                                                            True\n",
      "torch.outer                                                           outer                                                            True\n",
      "torch.pairwise_distance                                               pairwise_distance                                                True\n",
      "torch.pdist                                                           pdist                                                            True\n",
      "torch.permute                                                         permute                                                          True\n",
      "torch.permute_copy                                                    permute_copy                                                     True\n",
      "torch.pinverse                                                        pinverse                                                         True\n",
      "torch.pixel_shuffle                                                   pixel_shuffle                                                    True\n",
      "torch.pixel_unshuffle                                                 pixel_unshuffle                                                  True\n",
      "torch.poisson                                                         poisson                                                          True\n",
      "torch.poisson_nll_loss                                                poisson_nll_loss                                                 True\n",
      "torch.polar                                                           polar                                                            True\n",
      "torch.polygamma                                                       polygamma                                                        True\n",
      "torch.positive                                                        positive                                                         True\n",
      "torch.pow                                                             pow                                                              True\n",
      "torch.prelu                                                           prelu                                                            True\n",
      "torch.prod                                                            prod                                                             True\n",
      "torch.promote_types                                                   promote_types                                                    True\n",
      "torch.put                                                             put                                                              True\n",
      "torch.q_per_channel_axis                                              q_per_channel_axis                                               True\n",
      "torch.q_per_channel_scales                                            q_per_channel_scales                                             True\n",
      "torch.q_per_channel_zero_points                                       q_per_channel_zero_points                                        True\n",
      "torch.q_scale                                                         q_scale                                                          True\n",
      "torch.q_zero_point                                                    q_zero_point                                                     True\n",
      "torch.qr                                                              qr                                                               True\n",
      "torch.quantile                                                        quantile                                                         True\n",
      "torch.quantize_per_channel                                            quantize_per_channel                                             True\n",
      "torch.quantize_per_tensor                                             quantize_per_tensor                                              True\n",
      "torch.quantize_per_tensor_dynamic                                     quantize_per_tensor_dynamic                                      True\n",
      "torch.quantized_batch_norm                                            quantized_batch_norm                                             True\n",
      "torch.quantized_gru_cell                                              quantized_gru_cell                                               True\n",
      "torch.quantized_lstm_cell                                             quantized_lstm_cell                                              True\n",
      "torch.quantized_max_pool1d                                            quantized_max_pool1d                                             True\n",
      "torch.quantized_max_pool2d                                            quantized_max_pool2d                                             True\n",
      "torch.quantized_max_pool3d                                            quantized_max_pool3d                                             True\n",
      "torch.quantized_rnn_relu_cell                                         quantized_rnn_relu_cell                                          True\n",
      "torch.quantized_rnn_tanh_cell                                         quantized_rnn_tanh_cell                                          True\n",
      "torch.rad2deg                                                         rad2deg                                                          True\n",
      "torch.rad2deg_                                                        rad2deg_                                                         True\n",
      "torch.rand                                                            rand                                                             True\n",
      "torch.rand_like                                                       rand_like                                                        True\n",
      "torch.randint                                                         randint                                                          True\n",
      "torch.randint_like                                                    randint_like                                                     True\n",
      "torch.randn                                                           randn                                                            True\n",
      "torch.randn_like                                                      randn_like                                                       True\n",
      "torch.randperm                                                        randperm                                                         True\n",
      "torch.range                                                           range                                                            True\n",
      "torch.ravel                                                           ravel                                                            True\n",
      "torch.real                                                            real                                                             True\n",
      "torch.reciprocal                                                      reciprocal                                                       True\n",
      "torch.reciprocal_                                                     reciprocal_                                                      True\n",
      "torch.relu                                                            relu                                                             True\n",
      "torch.relu_                                                           relu_                                                            True\n",
      "torch.remainder                                                       remainder                                                        True\n",
      "torch.renorm                                                          renorm                                                           True\n",
      "torch.repeat_interleave                                               repeat_interleave                                                True\n",
      "torch.reshape                                                         reshape                                                          True\n",
      "torch.resize_as_                                                      resize_as_                                                       True\n",
      "torch.resize_as_sparse_                                               resize_as_sparse_                                                True\n",
      "torch.resolve_conj                                                    resolve_conj                                                     True\n",
      "torch.resolve_neg                                                     resolve_neg                                                      True\n",
      "torch.result_type                                                     result_type                                                      True\n",
      "torch.rnn_relu                                                        rnn_relu                                                         True\n",
      "torch.rnn_relu_cell                                                   rnn_relu_cell                                                    True\n",
      "torch.rnn_tanh                                                        rnn_tanh                                                         True\n",
      "torch.rnn_tanh_cell                                                   rnn_tanh_cell                                                    True\n",
      "torch.roll                                                            roll                                                             True\n",
      "torch.rot90                                                           rot90                                                            True\n",
      "torch.round                                                           round                                                            True\n",
      "torch.round_                                                          round_                                                           True\n",
      "torch.row_indices_copy                                                row_indices_copy                                                 True\n",
      "torch.row_stack                                                       row_stack                                                        True\n",
      "torch.rrelu                                                           rrelu                                                            True\n",
      "torch.rrelu_                                                          rrelu_                                                           True\n",
      "torch.rsqrt                                                           rsqrt                                                            True\n",
      "torch.rsqrt_                                                          rsqrt_                                                           True\n",
      "torch.rsub                                                            rsub                                                             True\n",
      "torch.saddmm                                                          saddmm                                                           True\n",
      "torch.scalar_tensor                                                   scalar_tensor                                                    True\n",
      "torch.scatter                                                         scatter                                                          True\n",
      "torch.scatter_add                                                     scatter_add                                                      True\n",
      "torch.scatter_reduce                                                  scatter_reduce                                                   True\n",
      "torch.searchsorted                                                    searchsorted                                                     True\n",
      "torch.segment_reduce                                                  segment_reduce                                                   True\n",
      "torch.segment_reduce                                                  _segment_reduce                                                  True\n",
      "torch.select                                                          select                                                           True\n",
      "torch.select_copy                                                     select_copy                                                      True\n",
      "torch.select_scatter                                                  select_scatter                                                   True\n",
      "torch.selu                                                            selu                                                             True\n",
      "torch.selu_                                                           selu_                                                            True\n",
      "torch.sgn                                                             sgn                                                              True\n",
      "torch.sigmoid                                                         sigmoid                                                          True\n",
      "torch.sigmoid_                                                        sigmoid_                                                         True\n",
      "torch.sign                                                            sign                                                             True\n",
      "torch.signbit                                                         signbit                                                          True\n",
      "torch.sin                                                             sin                                                              True\n",
      "torch.sin_                                                            sin_                                                             True\n",
      "torch.sinc                                                            sinc                                                             True\n",
      "torch.sinc_                                                           sinc_                                                            True\n",
      "torch.sinh                                                            sinh                                                             True\n",
      "torch.sinh_                                                           sinh_                                                            True\n",
      "torch.slice_copy                                                      slice_copy                                                       True\n",
      "torch.slice_scatter                                                   slice_scatter                                                    True\n",
      "torch.slogdet                                                         slogdet                                                          True\n",
      "torch.smm                                                             smm                                                              True\n",
      "torch.softmax                                                         softmax                                                          True\n",
      "torch.sort                                                            sort                                                             True\n",
      "torch.sparse_bsc_tensor                                               sparse_bsc_tensor                                                True\n",
      "torch.sparse_bsr_tensor                                               sparse_bsr_tensor                                                True\n",
      "torch.sparse_compressed_tensor                                        sparse_compressed_tensor                                         True\n",
      "torch.sparse_coo_tensor                                               sparse_coo_tensor                                                True\n",
      "torch.sparse_csc_tensor                                               sparse_csc_tensor                                                True\n",
      "torch.sparse_csr_tensor                                               sparse_csr_tensor                                                True\n",
      "torch.functional.split                                                split                                                            True\n",
      "torch.split_copy                                                      split_copy                                                       True\n",
      "torch.split_with_sizes                                                split_with_sizes                                                 True\n",
      "torch.split_with_sizes_copy                                           split_with_sizes_copy                                            True\n",
      "torch.spmm                                                            spmm                                                             True\n",
      "torch.sqrt                                                            sqrt                                                             True\n",
      "torch.sqrt_                                                           sqrt_                                                            True\n",
      "torch.square                                                          square                                                           True\n",
      "torch.square_                                                         square_                                                          True\n",
      "torch.squeeze                                                         squeeze                                                          True\n",
      "torch.squeeze_copy                                                    squeeze_copy                                                     True\n",
      "torch.sspaddmm                                                        sspaddmm                                                         True\n",
      "torch.stack                                                           stack                                                            True\n",
      "torch.std                                                             std                                                              True\n",
      "torch.std_mean                                                        std_mean                                                         True\n",
      "torch.functional.stft                                                 stft                                                             True\n",
      "torch.sub                                                             sub                                                              True\n",
      "torch.subtract                                                        subtract                                                         True\n",
      "torch.sum                                                             sum                                                              True\n",
      "torch.svd                                                             svd                                                              True\n",
      "torch.swapaxes                                                        swapaxes                                                         True\n",
      "torch.swapdims                                                        swapdims                                                         True\n",
      "torch.sym_constrain_range                                             sym_constrain_range                                              True\n",
      "torch.sym_constrain_range_for_size                                    sym_constrain_range_for_size                                     True\n",
      "torch.t                                                               t                                                                True\n",
      "torch.t_copy                                                          t_copy                                                           True\n",
      "torch.take                                                            take                                                             True\n",
      "torch.take_along_dim                                                  take_along_dim                                                   True\n",
      "torch.tan                                                             tan                                                              True\n",
      "torch.tan_                                                            tan_                                                             True\n",
      "torch.tanh                                                            tanh                                                             True\n",
      "torch.tanh_                                                           tanh_                                                            True\n",
      "torch.tensor                                                          tensor                                                           True\n",
      "torch.tensor_split                                                    tensor_split                                                     True\n",
      "torch.functional.tensordot                                            tensordot                                                        True\n",
      "torch.threshold                                                       threshold                                                        True\n",
      "torch.threshold_                                                      threshold_                                                       True\n",
      "torch.tile                                                            tile                                                             True\n",
      "torch.topk                                                            topk                                                             True\n",
      "torch.trace                                                           trace                                                            True\n",
      "torch.transpose                                                       transpose                                                        True\n",
      "torch.transpose_copy                                                  transpose_copy                                                   True\n",
      "torch.trapezoid                                                       trapezoid                                                        True\n",
      "torch.trapz                                                           trapz                                                            True\n",
      "torch.triangular_solve                                                triangular_solve                                                 True\n",
      "torch.tril                                                            tril                                                             True\n",
      "torch.tril_indices                                                    tril_indices                                                     True\n",
      "torch.triplet_margin_loss                                             triplet_margin_loss                                              True\n",
      "torch.triu                                                            triu                                                             True\n",
      "torch.triu_indices                                                    triu_indices                                                     True\n",
      "torch.true_divide                                                     true_divide                                                      True\n",
      "torch.trunc                                                           trunc                                                            True\n",
      "torch.trunc_                                                          trunc_                                                           True\n",
      "torch.unbind                                                          unbind                                                           True\n",
      "torch.unbind_copy                                                     unbind_copy                                                      True\n",
      "torch.unflatten                                                       unflatten                                                        True\n",
      "torch.unfold_copy                                                     unfold_copy                                                      True\n",
      "torch.functional.unique_consecutive                                   unique_consecutive                                               True\n",
      "torch.unsafe_chunk                                                    unsafe_chunk                                                     True\n",
      "torch.unsafe_split                                                    unsafe_split                                                     True\n",
      "torch.unsafe_split_with_sizes                                         unsafe_split_with_sizes                                          True\n",
      "torch.unsqueeze                                                       unsqueeze                                                        True\n",
      "torch.unsqueeze_copy                                                  unsqueeze_copy                                                   True\n",
      "torch.values_copy                                                     values_copy                                                      True\n",
      "torch.vander                                                          vander                                                           True\n",
      "torch.var                                                             var                                                              True\n",
      "torch.var_mean                                                        var_mean                                                         True\n",
      "torch.vdot                                                            vdot                                                             True\n",
      "torch.view_as_complex                                                 view_as_complex                                                  True\n",
      "torch.view_as_complex_copy                                            view_as_complex_copy                                             True\n",
      "torch.view_as_real                                                    view_as_real                                                     True\n",
      "torch.view_as_real_copy                                               view_as_real_copy                                                True\n",
      "torch.view_copy                                                       view_copy                                                        True\n",
      "torch.vsplit                                                          vsplit                                                           True\n",
      "torch.vstack                                                          vstack                                                           True\n",
      "torch.where                                                           where                                                            True\n",
      "torch.xlogy                                                           xlogy                                                            True\n",
      "torch.xlogy_                                                          xlogy_                                                           True\n",
      "torch.zero_                                                           zero_                                                            True\n",
      "torch.zeros                                                           zeros                                                            True\n",
      "torch.zeros_like                                                      zeros_like                                                       True\n",
      "torch._compile                                                        _compile                                                         True\n",
      "torch._compile._disable_dynamo                                        _disable_dynamo                                                  True\n",
      "torch._VF                                                             _VF                                                              True\n",
      "torch.distributed                                                     distributed                                                      True\n",
      "torch.package                                                         package                                                          True\n",
      "torch._awaits                                                         _awaits                                                          True\n",
      "torch.futures                                                         futures                                                          True\n",
      "torch._jit_internal                                                   _jit_internal                                                    True\n",
      "torch._vmap_internals                                                 _vmap_internals                                                  True\n",
      "torch._functorch                                                      _functorch                                                       True\n",
      "torch._ops                                                            _ops                                                             True\n",
      "torch.testing                                                         testing                                                          True\n",
      "torch.autograd                                                        autograd                                                         True\n",
      "torch.nn                                                              nn                                                               True\n",
      "torch._linalg_utils                                                   _linalg_utils                                                    True\n",
      "torch._lowrank                                                        _lowrank                                                         True\n",
      "torch.functional                                                      functional                                                       True\n",
      "torch.functional.broadcast_shapes                                     broadcast_shapes                                                 True\n",
      "torch.functional.lu                                                   lu                                                               True\n",
      "torch._lowrank.pca_lowrank                                            pca_lowrank                                                      True\n",
      "torch._lowrank.svd_lowrank                                            svd_lowrank                                                      True\n",
      "torch.functional.unique                                               unique                                                           True\n",
      "torch._assert                                                         _assert                                                          True\n",
      "torch.cpu                                                             cpu                                                              True\n",
      "torch.mps                                                             mps                                                              True\n",
      "torch.autograd.grad_mode.no_grad                                      no_grad                                                          True\n",
      "torch.autograd.grad_mode.enable_grad                                  enable_grad                                                      True\n",
      "torch.autograd.grad_mode.set_grad_enabled                             set_grad_enabled                                                 True\n",
      "torch.autograd.grad_mode.inference_mode                               inference_mode                                                   True\n",
      "torch.fft                                                             fft                                                              True\n",
      "torch.nested                                                          nested                                                           True\n",
      "torch.signal                                                          signal                                                           True\n",
      "torch.signal.windows                                                  windows                                                          True\n",
      "torch.optim                                                           optim                                                            True\n",
      "torch                                                                 torch                                                            True\n",
      "torch.multiprocessing                                                 multiprocessing                                                  True\n",
      "torch.special                                                         special                                                          True\n",
      "torch.library                                                         library                                                          True\n",
      "torch.backends                                                        backends                                                         True\n",
      "torch._classes                                                        _classes                                                         True\n",
      "torch.jit                                                             jit                                                              True\n",
      "torch.linalg                                                          linalg                                                           True\n",
      "torch.hub                                                             hub                                                              True\n",
      "torch.distributions                                                   distributions                                                    True\n",
      "torch.profiler                                                        profiler                                                         True\n",
      "torch.ao                                                              ao                                                               True\n",
      "torch.compiled_with_cxx11_abi                                         compiled_with_cxx11_abi                                          True\n",
      "torch.ops                                                             ops                                                              True\n",
      "torch.classes                                                         classes                                                          True\n",
      "torch.fx                                                              fx                                                               True\n",
      "torch.quantization                                                    quantization                                                     True\n",
      "torch.quasirandom                                                     quasirandom                                                      True\n",
      "torch._lobpcg                                                         _lobpcg                                                          True\n",
      "torch._lobpcg.lobpcg                                                  lobpcg                                                           True\n",
      "<class 'torch._ops.OpOverloadPacket'>                                 quantized_lstm                                                   False\n",
      "<class 'torch._ops.OpOverloadPacket'>                                 quantized_gru                                                    False\n",
      "torch.utils.dlpack.from_dlpack                                        from_dlpack                                                      True\n",
      "torch._C._to_dlpack                                                   to_dlpack                                                        True\n",
      "torch._prims_common                                                   _prims_common                                                    True\n",
      "torch.masked                                                          masked                                                           True\n",
      "torch._linalg_utils.matrix_rank                                       matrix_rank                                                      True\n",
      "torch._linalg_utils.eig                                               eig                                                              True\n",
      "torch._linalg_utils.solve                                             solve                                                            True\n",
      "torch._linalg_utils.lstsq                                             lstsq                                                            True\n",
      "torch._linalg_utils._symeig                                           symeig                                                           True\n",
      "torch._TorchCompileInductorWrapper                                    _TorchCompileInductorWrapper                                     True\n",
      "torch._TorchCompileWrapper                                            _TorchCompileWrapper                                             True\n",
      "torch.compile                                                         compile                                                          True\n",
      "torch._guards                                                         _guards                                                          True\n",
      "torch._dispatch                                                       _dispatch                                                        True\n",
      "torch._custom_op                                                      _custom_op                                                       True\n",
      "torch._logging                                                        _logging                                                         True\n",
      "torch._subclasses                                                     _subclasses                                                      True\n",
      "torch.export                                                          export                                                           True\n",
      "torch._register_device_module                                         _register_device_module                                          True\n",
      "torch.return_types                                                    return_types                                                     True\n",
      "torch._higher_order_ops                                               _higher_order_ops                                                True\n",
      "torch._prims                                                          _prims                                                           True\n",
      "torch._refs                                                           _refs                                                            True\n",
      "torch._decomp                                                         _decomp                                                          True\n",
      "torch._meta_registrations                                             _meta_registrations                                              True\n",
      "torch.func                                                            func                                                             True\n",
      "torch.func.vmap                                                       vmap                                                             True\n",
      "torch._sparse_coo_tensor_unsafe                                       _sparse_coo_tensor_unsafe                                        True\n",
      "torch.compiler                                                        compiler                                                         True\n",
      "torch._TritonLibrary                                                  _TritonLibrary                                                   True\n"
     ]
    }
   ],
   "source": [
    "for name in getAttributes(torch):\n",
    "    try:\n",
    "        attr = getattr(torch, name)\n",
    "        print(f\"{getAPIName(attr):<70}{name:<65}{isFromModule(attr, 'torch')}\");\n",
    "    except Exception as e:\n",
    "        raise NameError(f\"The attribution that cause error is {name}\") from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7f71228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "function"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(torch._import_dotted_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe312cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "isFromModule(torch._utils, \"torch\")\n",
    "getAPIName(torch.quantized_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a49551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bdd551",
   "metadata": {},
   "outputs": [],
   "source": [
    "getAttributes(torch).index(\"matmul\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074e1b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(*args):\n",
    "    return sum(args);\n",
    "add(2,7,4,6,9,5,3,3,8,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357fffe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8c0a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "isDecorated(torch._C.Block),isinstance(torch._C.Block, type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfd8b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "getAttributes(torch).index(\"list_backends\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6a456b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch._utils.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1cd5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Callable.__module__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cb93f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.builtins.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7471ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.optim.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceed896f",
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(torch.Size, type),torch.Size.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97cdfeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time.time\n",
      "time.time_ns\n",
      "time.sleep\n",
      "time.gmtime\n",
      "time.localtime\n",
      "time.asctime\n",
      "time.ctime\n",
      "time.mktime\n",
      "time.strftime\n",
      "time.strptime\n",
      "time.monotonic\n",
      "time.monotonic_ns\n",
      "time.process_time\n",
      "time.process_time_ns\n",
      "time.thread_time\n",
      "time.thread_time_ns\n",
      "time.perf_counter\n",
      "time.perf_counter_ns\n",
      "time.get_clock_info\n",
      "time.struct_time\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for na in getAttributes(time):\n",
    "    attr = getattr(time, na);\n",
    "    print(getAPIName(attr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0214a24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
